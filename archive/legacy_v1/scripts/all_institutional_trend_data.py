#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import logging
import pandas as pd
from datetime import datetime, timedelta
import time
import os
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from tqdm import tqdm
import concurrent.futures
from typing import Dict, List, Optional, Tuple
import json
import threading
from dataclasses import dataclass, asdict
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('institutional_trend_analyzer.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class TrendConfig:
    """íŠ¸ë Œë“œ ë¶„ì„ ì„¤ì •"""
    strong_buy_inst: int = 3000000      # ê¸°ê´€ ê°•ë§¤ìˆ˜ ê¸°ì¤€ (3ë°±ë§Œì£¼)
    buy_inst: int = 1000000             # ê¸°ê´€ ë§¤ìˆ˜ ê¸°ì¤€ (1ë°±ë§Œì£¼)
    neutral_inst: int = -500000         # ê¸°ê´€ ì¤‘ë¦½ ê¸°ì¤€
    sell_inst: int = -1000000           # ê¸°ê´€ ë§¤ë„ ê¸°ì¤€
    strong_sell_inst: int = -3000000    # ê¸°ê´€ ê°•ë§¤ë„ ê¸°ì¤€

    strong_buy_foreign: int = 5000000   # ì™¸êµ­ì¸ ê°•ë§¤ìˆ˜ ê¸°ì¤€ (5ë°±ë§Œì£¼)
    buy_foreign: int = 2000000          # ì™¸êµ­ì¸ ë§¤ìˆ˜ ê¸°ì¤€ (2ë°±ë§Œì£¼)
    neutral_foreign: int = -1000000     # ì™¸êµ­ì¸ ì¤‘ë¦½ ê¸°ì¤€
    sell_foreign: int = -2000000        # ì™¸êµ­ì¸ ë§¤ë„ ê¸°ì¤€
    strong_sell_foreign: int = -5000000 # ì™¸êµ­ì¸ ê°•ë§¤ë„ ê¸°ì¤€

    high_ratio_inst: float = 8.0        # ê¸°ê´€ ê³ ë¹„ìœ¨ ê¸°ì¤€
    high_ratio_foreign: float = 12.0    # ì™¸êµ­ì¸ ê³ ë¹„ìœ¨ ê¸°ì¤€

    accumulation_volume_threshold: int = 1000000  # ë§¤ì§‘ íŒë‹¨ ìµœì†Œ ê±°ë˜ëŸ‰

@dataclass
class InstitutionalData:
    """ê¸°ê´€ ë°ì´í„° êµ¬ì¡°"""
    ticker: str
    scrape_date: str
    data_source: str
    total_days: int

    # ê¸°ê´€ ìˆœë§¤ë§¤ëŸ‰
    institutional_net_buy_60d: int = 0
    institutional_net_buy_20d: int = 0
    institutional_net_buy_10d: int = 0
    institutional_net_buy_5d: int = 0

    # ì™¸êµ­ì¸ ìˆœë§¤ë§¤ëŸ‰
    foreign_net_buy_60d: int = 0
    foreign_net_buy_20d: int = 0
    foreign_net_buy_10d: int = 0
    foreign_net_buy_5d: int = 0

    # ê±°ë˜ëŸ‰
    total_volume_60d: int = 0
    total_volume_20d: int = 0
    total_volume_10d: int = 0
    total_volume_5d: int = 0

    # ê±°ë˜ëŸ‰ ëŒ€ë¹„ ë¹„ìœ¨
    institutional_ratio_60d: float = 0.0
    institutional_ratio_20d: float = 0.0
    institutional_ratio_10d: float = 0.0
    institutional_ratio_5d: float = 0.0

    foreign_ratio_60d: float = 0.0
    foreign_ratio_20d: float = 0.0
    foreign_ratio_10d: float = 0.0
    foreign_ratio_5d: float = 0.0

    # ê°€ê²© ë³€í™”
    price_change_60d: float = 0.0

    # íŠ¸ë Œë“œ ë¶„ì„
    institutional_trend: str = 'neutral'
    foreign_trend: str = 'neutral'
    supply_demand_index: float = 50.0
    supply_demand_stage: str = 'ì¤‘ë¦½'

    # ë§¤ì§‘ ì‹ í˜¸
    strong_accumulation: int = 0
    accumulation_signal: int = 0
    accumulation_intensity: str = 'ë³´í†µ'
    trend_strength: str = 'ë³´í†µ'

    # ì¶”ê°€ ë¶„ì„ ì§€í‘œ
    momentum_score: float = 0.0
    consistency_score: float = 0.0
    volume_pattern: str = 'ë³´í†µ'
    risk_level: str = 'ì¤‘ê°„'

class EnhancedKoreanInstitutionalTrendAnalyzer:
    """í•œêµ­ ì£¼ì‹ ì „ì²´ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° (ì—…ê·¸ë ˆì´ë“œ ë²„ì „)"""

    def __init__(self, data_dir: str = None, config: TrendConfig = None):
        # DATA_DIR í™˜ê²½ ë³€ìˆ˜ ìš°ì„  ì‚¬ìš©
        if data_dir is None:
            data_dir = os.getenv('DATA_DIR', '.')
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

        self.all_institutional_csv_path = self.data_dir / 'all_institutional_trend_data.csv'
        self.config = config or TrendConfig()

        # ì„¸ì…˜ ì„¤ì • (ì—°ê²° í’€ë§)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })

        # ë„¤ì´ë²„ ê¸ˆìœµ URL íŒ¨í„´
        self.base_url = "https://finance.naver.com/item/frgn.naver"

        # ìºì‹œ ë° ì„±ëŠ¥ ìµœì í™”
        self._cache = {}
        self._cache_expiry = {}
        self.cache_duration = 300  # 5ë¶„

        # ìŠ¤ë ˆë“œ ë½
        self._lock = threading.Lock()

        # ìš”ì²­ ì œí•œ (rate limiting)
        self.request_delay = 0.3
        self.max_retries = 3
        self.backoff_factor = 1.5

        logger.info(f"âœ… Enhanced ê¸°ê´€ íŠ¸ë Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {self.data_dir}")

    def __del__(self):
        """ì†Œë©¸ì - ì„¸ì…˜ ì •ë¦¬"""
        if hasattr(self, 'session'):
            self.session.close()

    def load_all_stock_info(self) -> pd.DataFrame:
        """ì „ì²´ ì£¼ì‹ ì •ë³´ ë¡œë“œ (ìºì‹œ ì§€ì›)"""
        cache_key = 'stock_info'

        # ìºì‹œ í™•ì¸
        if self._is_cache_valid(cache_key):
            return self._cache[cache_key]

        try:
            stock_info_path = self.data_dir / 'korean_stocks_list.csv'

            if stock_info_path.exists():
                df = pd.read_csv(stock_info_path, encoding='utf-8')
                logger.info(f"âœ… ì „ì²´ ì£¼ì‹ ì •ë³´ ë¡œë“œ: {len(df)}ê°œ ì¢…ëª©")

                # ìºì‹œ ì €ì¥
                self._cache[cache_key] = df
                self._cache_expiry[cache_key] = time.time() + self.cache_duration

                return df
            else:
                logger.error("âŒ stock_info.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return pd.DataFrame()

        except Exception as e:
            logger.error(f"âŒ ì£¼ì‹ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def _is_cache_valid(self, key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        return (key in self._cache and
                key in self._cache_expiry and
                time.time() < self._cache_expiry[key])

    def _make_request_with_retry(self, url: str, timeout: int = 15) -> Optional[requests.Response]:
        """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” HTTP ìš”ì²­"""
        for attempt in range(self.max_retries):
            try:
                response = self.session.get(url, timeout=timeout)
                response.raise_for_status()

                # ìš”ì²­ ì œí•œ
                time.sleep(self.request_delay)
                return response

            except requests.exceptions.RequestException as e:
                wait_time = self.backoff_factor ** attempt
                logger.warning(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{self.max_retries}): {e}")

                if attempt < self.max_retries - 1:
                    logger.info(f"ğŸ”„ {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {url}")
                    return None

        return None

    def scrape_naver_institutional_trend_data(self, ticker: str) -> Optional[InstitutionalData]:
        """ë„¤ì´ë²„ì—ì„œ 60ì¼ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë°ì´í„° ìŠ¤í¬ë˜í•‘ (ì—…ê·¸ë ˆì´ë“œ)"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"institutional_{ticker}"
            if self._is_cache_valid(cache_key):
                return self._cache[cache_key]

            # ë„¤ì´ë²„ ê¸ˆìœµ URL
            url = f"{self.base_url}?code={ticker}"

            # ì›¹í˜ì´ì§€ ìš”ì²­
            response = self._make_request_with_retry(url)
            if not response:
                return self._create_fallback_data(ticker)

            # í•œê¸€ ì¸ì½”ë”© ì„¤ì •
            response.encoding = 'euc-kr'

            # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')

            # ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ í…Œì´ë¸” ì°¾ê¸°
            daily_data = self._extract_daily_data(soup)

            # íŠ¸ë Œë“œ ë¶„ì„
            if daily_data and len(daily_data) >= 5:  # ìµœì†Œ 5ì¼ ë°ì´í„° í•„ìš”
                institutional_data = self._analyze_comprehensive_trend(ticker, daily_data)

                # ìºì‹œ ì €ì¥
                with self._lock:
                    self._cache[cache_key] = institutional_data
                    self._cache_expiry[cache_key] = time.time() + self.cache_duration

                return institutional_data
            else:
                logger.warning(f"âš ï¸ {ticker} ì¶©ë¶„í•œ ë°ì´í„° ì—†ìŒ (ìˆ˜ì§‘ëœ ì¼ìˆ˜: {len(daily_data) if daily_data else 0})")
                return self._create_fallback_data(ticker)

        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return self._create_fallback_data(ticker)

    def _extract_daily_data(self, soup: BeautifulSoup) -> List[Dict]:
        """ì¼ë³„ ë°ì´í„° ì¶”ì¶œ"""
        daily_data = []

        try:
            # í…Œì´ë¸” ì°¾ê¸° - ë” ì •í™•í•œ ì„ íƒì ì‚¬ìš©
            tables = soup.find_all('table', class_='type2')
            if not tables:
                tables = soup.find_all('table')

            for table in tables:
                rows = table.find_all('tr')

                for row in rows:
                    cells = row.find_all(['td', 'th'])

                    if len(cells) >= 7:  # ê¸°ê´€/ì™¸êµ­ì¸ ë°ì´í„°ê°€ ìˆëŠ” í–‰
                        try:
                            # ë‚ ì§œ í™•ì¸ (ë” ê°•ê±´í•œ ì •ê·œì‹)
                            date_cell = cells[0].get_text(strip=True)
                            if not re.match(r'\d{4}\.\d{2}\.\d{2}', date_cell):
                                continue

                            # ë°ì´í„° ì¶”ì¶œ
                            close_price = self._parse_number(cells[1].get_text(strip=True))
                            volume = self._parse_number(cells[4].get_text(strip=True))
                            inst_value = self._parse_number_with_sign(cells[5].get_text(strip=True))
                            foreign_value = self._parse_number_with_sign(cells[6].get_text(strip=True))

                            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                            if volume > 0:  # ê±°ë˜ëŸ‰ì´ ìˆëŠ” ê²½ìš°ë§Œ
                                daily_data.append({
                                    'date': date_cell,
                                    'close_price': close_price,
                                    'volume': volume,
                                    'institutional_net_buy': inst_value,
                                    'foreign_net_buy': foreign_value
                                })

                                # 60ì¼ ë°ì´í„°ë§Œ ìˆ˜ì§‘
                                if len(daily_data) >= 60:
                                    break

                        except (IndexError, ValueError) as e:
                            continue

                if len(daily_data) >= 60:
                    break

            return daily_data

        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë³„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _parse_number(self, text: str) -> int:
        """ìˆ«ì íŒŒì‹± (ê°œì„ ëœ ë²„ì „)"""
        try:
            # ì‰¼í‘œ ì œê±° ë° ê³µë°± ì œê±°
            text = re.sub(r'[,\s]', '', text)

            # ìˆ«ìë§Œ ì¶”ì¶œ
            numbers = re.findall(r'\d+', text)
            return int(numbers[0]) if numbers else 0

        except:
            return 0

    def _parse_number_with_sign(self, text: str) -> int:
        """ë¶€í˜¸ë¥¼ í¬í•¨í•œ ìˆ«ì íŒŒì‹± (ê°œì„ ëœ ë²„ì „)"""
        try:
            # ì‰¼í‘œ ì œê±° ë° ê³µë°± ì œê±°
            text = re.sub(r'[,\s]', '', text)

            # + ë˜ëŠ” - ê¸°í˜¸ì™€ ìˆ«ì ì¶”ì¶œ
            if '+' in text or 'â–²' in text:
                numbers = re.findall(r'\d+', text)
                return int(numbers[0]) if numbers else 0
            elif '-' in text or 'â–¼' in text:
                numbers = re.findall(r'\d+', text)
                return -int(numbers[0]) if numbers else 0
            else:
                numbers = re.findall(r'\d+', text)
                return int(numbers[0]) if numbers else 0

        except:
            return 0

    def _analyze_comprehensive_trend(self, ticker: str, daily_data: List[Dict]) -> InstitutionalData:
        """ì¢…í•©ì ì¸ íŠ¸ë Œë“œ ë¶„ì„ (ì—…ê·¸ë ˆì´ë“œ)"""
        try:
            df = pd.DataFrame(daily_data)

            # ê¸°ê°„ë³„ ë°ì´í„° ë¶„í• 
            periods = {
                '60d': df,
                '20d': df.head(20),
                '10d': df.head(10),
                '5d': df.head(5)
            }

            # ê¸°ë³¸ ì§€í‘œ ê³„ì‚°
            metrics = {}
            for period, data in periods.items():
                metrics[f'institutional_net_buy_{period}'] = int(data['institutional_net_buy'].sum())
                metrics[f'foreign_net_buy_{period}'] = int(data['foreign_net_buy'].sum())
                metrics[f'total_volume_{period}'] = int(data['volume'].sum())

                # ê±°ë˜ëŸ‰ ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚°
                total_volume = metrics[f'total_volume_{period}']
                if total_volume > 0:
                    metrics[f'institutional_ratio_{period}'] = round(
                        (metrics[f'institutional_net_buy_{period}'] / total_volume * 100), 2
                    )
                    metrics[f'foreign_ratio_{period}'] = round(
                        (metrics[f'foreign_net_buy_{period}'] / total_volume * 100), 2
                    )
                else:
                    metrics[f'institutional_ratio_{period}'] = 0.0
                    metrics[f'foreign_ratio_{period}'] = 0.0

            # ê°€ê²© ë³€í™” ê³„ì‚°
            price_change_60d = 0.0
            if len(df) >= 2:
                price_change_60d = round(
                    (df.iloc[0]['close_price'] - df.iloc[-1]['close_price']) / df.iloc[-1]['close_price'] * 100, 2
                )

            # ê³ ê¸‰ íŠ¸ë Œë“œ ë¶„ì„
            trend_analysis = self._advanced_trend_analysis(metrics)

            # ì¶”ê°€ ì§€í‘œ ê³„ì‚°
            additional_metrics = self._calculate_additional_metrics(df, metrics)

            # InstitutionalData ê°ì²´ ìƒì„±
            institutional_data = InstitutionalData(
                ticker=ticker,
                scrape_date=datetime.now().strftime('%Y-%m-%d'),
                data_source='naver_finance_enhanced',
                total_days=len(df),
                price_change_60d=price_change_60d,
                **metrics,
                **trend_analysis,
                **additional_metrics
            )

            return institutional_data

        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_fallback_data(ticker)

    def _advanced_trend_analysis(self, metrics: Dict) -> Dict:
        """ê³ ê¸‰ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            # ê¸°ê´€ íŠ¸ë Œë“œ ë¶„ì„
            inst_trend = self._determine_advanced_trend(
                metrics['institutional_net_buy_60d'],
                metrics['institutional_net_buy_20d'],
                metrics['institutional_net_buy_5d'],
                metrics['institutional_ratio_20d'],
                'institutional'
            )

            # ì™¸êµ­ì¸ íŠ¸ë Œë“œ ë¶„ì„
            foreign_trend = self._determine_advanced_trend(
                metrics['foreign_net_buy_60d'],
                metrics['foreign_net_buy_20d'],
                metrics['foreign_net_buy_5d'],
                metrics['foreign_ratio_20d'],
                'foreign'
            )

            # ìˆ˜ê¸‰ ì§€ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)
            supply_demand_index = self._calculate_enhanced_supply_demand_index(metrics)

            # ìˆ˜ê¸‰ ë‹¨ê³„ íŒë‹¨
            supply_demand_stage = self._determine_supply_demand_stage(supply_demand_index)

            # ë§¤ì§‘ ì‹ í˜¸ ë¶„ì„
            accumulation_analysis = self._analyze_accumulation_signals(metrics)

            # íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚°
            trend_strength = self._calculate_trend_strength(metrics)

            return {
                'institutional_trend': inst_trend,
                'foreign_trend': foreign_trend,
                'supply_demand_index': round(supply_demand_index, 1),
                'supply_demand_stage': supply_demand_stage,
                'trend_strength': trend_strength,
                **accumulation_analysis
            }

        except Exception as e:
            logger.warning(f"âš ï¸ ê³ ê¸‰ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'institutional_trend': 'neutral',
                'foreign_trend': 'neutral',
                'supply_demand_index': 50.0,
                'supply_demand_stage': 'ì¤‘ë¦½',
                'strong_accumulation': 0,
                'accumulation_signal': 0,
                'accumulation_intensity': 'ë³´í†µ',
                'trend_strength': 'ë³´í†µ'
            }

    def _determine_advanced_trend(self, total_60d: int, total_20d: int, total_5d: int,
                                ratio_20d: float, investor_type: str) -> str:
        """ê³ ê¸‰ íŠ¸ë Œë“œ íŒë‹¨ (ê±°ë˜ëŸ‰ ë¹„ìœ¨ê³¼ ëª¨ë©˜í…€ ê³ ë ¤)"""
        try:
            if investor_type == 'institutional':
                # ê¸°ê´€ íŠ¸ë Œë“œ íŒë‹¨
                if (total_60d > self.config.strong_buy_inst and
                    total_5d > 0 and
                    ratio_20d > self.config.high_ratio_inst):
                    return 'strong_buying'
                elif (total_60d > self.config.buy_inst and
                      (ratio_20d > 3 or total_20d > total_60d * 0.4)):
                    return 'buying'
                elif (total_60d < self.config.strong_sell_inst and
                      ratio_20d < -self.config.high_ratio_inst):
                    return 'strong_selling'
                elif (total_60d < self.config.sell_inst and
                      (ratio_20d < -3 or total_20d < total_60d * 0.4)):
                    return 'selling'
                else:
                    return 'neutral'
            else:  # foreign
                # ì™¸êµ­ì¸ íŠ¸ë Œë“œ íŒë‹¨
                if (total_60d > self.config.strong_buy_foreign and
                    total_5d > 0 and
                    ratio_20d > self.config.high_ratio_foreign):
                    return 'strong_buying'
                elif (total_60d > self.config.buy_foreign and
                      (ratio_20d > 5 or total_20d > total_60d * 0.4)):
                    return 'buying'
                elif (total_60d < self.config.strong_sell_foreign and
                      ratio_20d < -self.config.high_ratio_foreign):
                    return 'strong_selling'
                elif (total_60d < self.config.sell_foreign and
                      (ratio_20d < -5 or total_20d < total_60d * 0.4)):
                    return 'selling'
                else:
                    return 'neutral'

        except Exception as e:
            logger.warning(f"âš ï¸ ê³ ê¸‰ íŠ¸ë Œë“œ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return 'neutral'

    def _calculate_enhanced_supply_demand_index(self, metrics: Dict) -> float:
        """í–¥ìƒëœ ìˆ˜ê¸‰ ì§€ìˆ˜ ê³„ì‚° (0-100)"""
        try:
            # ê¸°ê´€ ì ìˆ˜ (0-50)
            inst_score = self._calculate_investor_score(
                metrics['institutional_net_buy_60d'],
                metrics['institutional_net_buy_20d'],
                metrics['institutional_net_buy_5d'],
                metrics['institutional_ratio_20d'],
                'institutional'
            )

            # ì™¸êµ­ì¸ ì ìˆ˜ (0-50)
            foreign_score = self._calculate_investor_score(
                metrics['foreign_net_buy_60d'],
                metrics['foreign_net_buy_20d'],
                metrics['foreign_net_buy_5d'],
                metrics['foreign_ratio_20d'],
                'foreign'
            )

            # ê±°ë˜ëŸ‰ ê°€ì¤‘ì¹˜ ì ìš©
            volume_weight = min(metrics['total_volume_20d'] / 10000000, 1.0)  # ìµœëŒ€ 1ì²œë§Œì£¼ ê¸°ì¤€

            final_score = (inst_score + foreign_score) * (0.8 + 0.2 * volume_weight)

            return min(max(final_score, 0), 100)

        except Exception as e:
            logger.warning(f"âš ï¸ ìˆ˜ê¸‰ ì§€ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 50.0

    def _calculate_investor_score(self, total_60d: int, total_20d: int, total_5d: int,
                                ratio_20d: float, investor_type: str) -> float:
        """íˆ¬ììë³„ ì ìˆ˜ ê³„ì‚° (0-50)"""
        try:
            # ê¸°ë³¸ ì ìˆ˜ (ìˆœë§¤ë§¤ëŸ‰ ê¸°ì¤€)
            if investor_type == 'institutional':
                base_score = min(max(total_60d / 6000000 * 25 + 25, 0), 35)
            else:  # foreign
                base_score = min(max(total_60d / 10000000 * 25 + 25, 0), 35)

            # ìµœê·¼ í™œë™ ì ìˆ˜ (0-10)
            recent_score = min(max(total_20d / (total_60d + 1) * 10, 0), 10)

            # ê±°ë˜ëŸ‰ ë¹„ìœ¨ ì ìˆ˜ (0-5)
            ratio_score = min(max(ratio_20d / 10 * 2.5 + 2.5, 0), 5)

            return base_score + recent_score + ratio_score

        except Exception as e:
            logger.warning(f"âš ï¸ íˆ¬ìì ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 25.0

    def _analyze_accumulation_signals(self, metrics: Dict) -> Dict:
        """ë§¤ì§‘ ì‹ í˜¸ ë¶„ì„"""
        try:
            # ê°•í•œ ë§¤ì§‘ ì‹ í˜¸
            strong_accumulation = 0
            if (metrics['institutional_net_buy_20d'] > 2000000 and
                metrics['foreign_net_buy_20d'] > 3000000 and
                metrics['institutional_net_buy_5d'] > 0 and
                metrics['foreign_net_buy_5d'] > 0 and
                (metrics['institutional_ratio_20d'] > 8 or metrics['foreign_ratio_20d'] > 12) and
                metrics['total_volume_20d'] > self.config.accumulation_volume_threshold):
                strong_accumulation = 1

            # ì¼ë°˜ ë§¤ì§‘ ì‹ í˜¸
            accumulation_signal = 0
            if (metrics['institutional_net_buy_20d'] > 0 and
                metrics['foreign_net_buy_20d'] > 0 and
                (metrics['institutional_ratio_20d'] > 3 or metrics['foreign_ratio_20d'] > 5)):
                accumulation_signal = 1

            # ë§¤ì§‘ ê°•ë„
            total_ratio = metrics['institutional_ratio_20d'] + metrics['foreign_ratio_20d']
            if total_ratio > 25:
                accumulation_intensity = 'ë§¤ìš°ê°•í•¨'
            elif total_ratio > 15:
                accumulation_intensity = 'ê°•í•¨'
            elif total_ratio > 8:
                accumulation_intensity = 'ë³´í†µ'
            elif total_ratio > 0:
                accumulation_intensity = 'ì•½í•¨'
            else:
                accumulation_intensity = 'ë§¤ë„ì„¸'

            return {
                'strong_accumulation': strong_accumulation,
                'accumulation_signal': accumulation_signal,
                'accumulation_intensity': accumulation_intensity
            }

        except Exception as e:
            logger.warning(f"âš ï¸ ë§¤ì§‘ ì‹ í˜¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'strong_accumulation': 0,
                'accumulation_signal': 0,
                'accumulation_intensity': 'ë³´í†µ'
            }

    def _calculate_trend_strength(self, metrics: Dict) -> str:
        """íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚°"""
        try:
            total_net_buy = metrics['institutional_net_buy_60d'] + metrics['foreign_net_buy_60d']
            total_ratio = metrics['institutional_ratio_20d'] + metrics['foreign_ratio_20d']

            # ê±°ë˜ëŸ‰ ë¹„ìœ¨ì„ ê³ ë ¤í•œ ê°•ë„ íŒë‹¨
            if total_ratio > 20 and total_net_buy > 5000000:
                return 'ë§¤ìš°ê°•í•¨'
            elif total_ratio > 12 and total_net_buy > 2000000:
                return 'ê°•í•¨'
            elif total_ratio > 6 or total_net_buy > 1000000:
                return 'ë³´í†µ'
            elif total_ratio > 0 or total_net_buy > -1000000:
                return 'ì•½í•¨'
            else:
                return 'ë§¤ìš°ì•½í•¨'

        except Exception as e:
            logger.warning(f"âš ï¸ íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 'ë³´í†µ'

    def _calculate_additional_metrics(self, df: pd.DataFrame, metrics: Dict) -> Dict:
        """ì¶”ê°€ ì§€í‘œ ê³„ì‚°"""
        try:
            # ëª¨ë©˜í…€ ì ìˆ˜ (ìµœê·¼ 5ì¼ vs ì´ì „ ê¸°ê°„)
            recent_5d_inst = metrics['institutional_net_buy_5d']
            prev_15d_inst = metrics['institutional_net_buy_20d'] - recent_5d_inst

            recent_5d_foreign = metrics['foreign_net_buy_5d']
            prev_15d_foreign = metrics['foreign_net_buy_20d'] - recent_5d_foreign

            if prev_15d_inst != 0:
                inst_momentum = (recent_5d_inst * 3 - prev_15d_inst) / abs(prev_15d_inst) * 100
            else:
                inst_momentum = 0

            if prev_15d_foreign != 0:
                foreign_momentum = (recent_5d_foreign * 3 - prev_15d_foreign) / abs(prev_15d_foreign) * 100
            else:
                foreign_momentum = 0

            momentum_score = round((inst_momentum + foreign_momentum) / 2, 1)

            # ì¼ê´€ì„± ì ìˆ˜ (ë³€ë™ì„± ê¸°ë°˜)
            if len(df) >= 10:
                inst_daily = df['institutional_net_buy'].head(10).tolist()
                foreign_daily = df['foreign_net_buy'].head(10).tolist()

                inst_consistency = 100 - min(np.std(inst_daily) / (abs(np.mean(inst_daily)) + 1) * 100, 100)
                foreign_consistency = 100 - min(np.std(foreign_daily) / (abs(np.mean(foreign_daily)) + 1) * 100, 100)

                consistency_score = round((inst_consistency + foreign_consistency) / 2, 1)
            else:
                consistency_score = 50.0

            # ê±°ë˜ëŸ‰ íŒ¨í„´
            avg_volume = metrics['total_volume_20d'] / 20
            recent_volume = metrics['total_volume_5d'] / 5

            if recent_volume > avg_volume * 1.5:
                volume_pattern = 'ê¸‰ì¦'
            elif recent_volume > avg_volume * 1.2:
                volume_pattern = 'ì¦ê°€'
            elif recent_volume < avg_volume * 0.7:
                volume_pattern = 'ê°ì†Œ'
            elif recent_volume < avg_volume * 0.5:
                volume_pattern = 'ê¸‰ê°'
            else:
                volume_pattern = 'ë³´í†µ'

            # ë¦¬ìŠ¤í¬ ë ˆë²¨
            total_ratio = abs(metrics['institutional_ratio_20d']) + abs(metrics['foreign_ratio_20d'])
            if total_ratio > 20:
                risk_level = 'ë†’ìŒ'
            elif total_ratio > 10:
                risk_level = 'ì¤‘ê°„'
            else:
                risk_level = 'ë‚®ìŒ'

            return {
                'momentum_score': momentum_score,
                'consistency_score': consistency_score,
                'volume_pattern': volume_pattern,
                'risk_level': risk_level
            }

        except Exception as e:
            logger.warning(f"âš ï¸ ì¶”ê°€ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                'momentum_score': 0.0,
                'consistency_score': 50.0,
                'volume_pattern': 'ë³´í†µ',
                'risk_level': 'ì¤‘ê°„'
            }

    def _determine_supply_demand_stage(self, supply_demand_index: float) -> str:
        """ìˆ˜ê¸‰ ë‹¨ê³„ íŒë‹¨"""
        if supply_demand_index >= 85:
            return "ê°•í•œë§¤ì§‘"
        elif supply_demand_index >= 70:
            return "ë§¤ì§‘"
        elif supply_demand_index >= 60:
            return "ì•½ë§¤ì§‘"
        elif supply_demand_index >= 40:
            return "ì¤‘ë¦½"
        elif supply_demand_index >= 30:
            return "ì•½ë¶„ì‚°"
        elif supply_demand_index >= 15:
            return "ë¶„ì‚°"
        else:
            return "ê°•í•œë¶„ì‚°"

    def _create_fallback_data(self, ticker: str) -> InstitutionalData:
        """ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ë°ì´í„°"""
        return InstitutionalData(
            ticker=ticker,
            scrape_date=datetime.now().strftime('%Y-%m-%d'),
            data_source='fallback_estimation',
            total_days=0
        )

    def download_all_institutional_data(self, max_stocks: int = None,
                                      max_workers: int = 5,
                                      save_interval: int = 100) -> pd.DataFrame:
        """ì „ì²´ ì£¼ì‹ ê¸°ê´€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë©€í‹°ìŠ¤ë ˆë”©)"""
        logger.info("ğŸš€ Enhanced ì „ì²´ ì£¼ì‹ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘...")

        # ì „ì²´ ì£¼ì‹ ì •ë³´ ë¡œë“œ
        stock_df = self.load_all_stock_info()

        if stock_df.empty:
            logger.error("âŒ ì£¼ì‹ ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()

        # ìµœëŒ€ ì¢…ëª© ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        if max_stocks:
            stock_df = stock_df.head(max_stocks)
            logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ìƒìœ„ {max_stocks}ê°œ ì¢…ëª©ë§Œ ì²˜ë¦¬")

        tickers = stock_df['ticker'].tolist()
        logger.info(f"ğŸ“ˆ ì´ {len(tickers)}ê°œ ì¢…ëª© ì²˜ë¦¬ ì˜ˆì • (ìŠ¤ë ˆë“œ: {max_workers}ê°œ)")

        results = []
        success_count = 0
        fail_count = 0

        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ì§„í–‰ë¥  í‘œì‹œ
            with tqdm(total=len(tickers), desc="ê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘") as pbar:
                # Future ê°ì²´ë“¤ì„ ì œì¶œ
                future_to_ticker = {
                    executor.submit(self.scrape_naver_institutional_trend_data, ticker): ticker
                    for ticker in tickers
                }

                # ê²°ê³¼ ìˆ˜ì§‘
                for i, future in enumerate(concurrent.futures.as_completed(future_to_ticker)):
                    ticker = future_to_ticker[future]

                    try:
                        institutional_data = future.result()
                        if institutional_data and institutional_data.total_days > 0:
                            results.append(asdict(institutional_data))
                            success_count += 1
                        else:
                            fail_count += 1

                    except Exception as e:
                        logger.warning(f"âš ï¸ {ticker} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        fail_count += 1

                    pbar.update(1)

                    # ì£¼ê¸°ì  ì¤‘ê°„ ì €ì¥ (ì œê±°ë¨)
                    # if (i + 1) % save_interval == 0 and results:
                    #     self._save_intermediate_results(results, i + 1)

        df = pd.DataFrame(results)

        logger.info(f"âœ… Enhanced ì „ì²´ ê¸°ê´€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logger.info(f"   ğŸ“Š ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"   âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        logger.info(f"   ğŸ“ˆ ì„±ê³µë¥ : {success_count/(success_count+fail_count)*100:.1f}%" if (success_count+fail_count) > 0 else "ì„±ê³µë¥ : 0%")

        return df

    def _save_intermediate_results(self, results: List[Dict], count: int):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        try:
            temp_df = pd.DataFrame(results)
            temp_path = self.data_dir / f'temp_institutional_data_{count}.csv'
            temp_df.to_csv(temp_path, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {temp_path} ({len(temp_df)}ê°œ)")
        except Exception as e:
            logger.warning(f"âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_institutional_data(self, df: pd.DataFrame) -> bool:
        """ê¸°ê´€ ìˆ˜ê¸‰ ë°ì´í„°ë¥¼ CSVì— ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        try:
            if df.empty:
                logger.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            # ë°ì´í„° ì •ë¦¬ ë° ê²€ì¦
            df_cleaned = self._clean_and_validate_data(df)

            # CSV íŒŒì¼ë¡œ ì €ì¥
            df_cleaned.to_csv(self.all_institutional_csv_path, index=False, encoding='utf-8-sig')

            # ìƒì„¸ ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = self._create_metadata(df_cleaned)
            metadata_df = pd.DataFrame([metadata])
            metadata_path = self.data_dir / 'all_institutional_metadata.csv'
            metadata_df.to_csv(metadata_path, index=False, encoding='utf-8-sig')

            # í†µê³„ ìš”ì•½ ì €ì¥
            summary = self._create_summary_statistics(df_cleaned)
            summary_df = pd.DataFrame([summary])
            summary_path = self.data_dir / 'institutional_summary.csv'
            summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')

            logger.info(f"ğŸ“ Enhanced ê¸°ê´€ íŠ¸ë Œë“œ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {self.all_institutional_csv_path}")
            logger.info(f"   ğŸ“Š ë°ì´í„° ê°œìˆ˜: {len(df_cleaned)}ê°œ")
            logger.info(f"   ğŸ“… ìˆ˜ì§‘ ì¼ì‹œ: {metadata['collection_date']}")

            return True

        except Exception as e:
            logger.error(f"âŒ ê¸°ê´€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _clean_and_validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ì •ë¦¬ ë° ê²€ì¦"""
        try:
            # ì¤‘ë³µ ì œê±°
            df_cleaned = df.drop_duplicates(subset=['ticker'])

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = [
                'ticker', 'institutional_net_buy_60d', 'foreign_net_buy_60d',
                'institutional_ratio_20d', 'foreign_ratio_20d', 'supply_demand_index'
            ]

            missing_columns = [col for col in required_columns if col not in df_cleaned.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}")

            # ë°ì´í„° íƒ€ì… ë³€í™˜
            numeric_columns = [col for col in df_cleaned.columns if 'ratio' in col or 'index' in col or 'score' in col or 'change' in col]
            for col in numeric_columns:
                if col in df_cleaned.columns:
                    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce').fillna(0)

            # ì´ìƒì¹˜ ì œê±° (ë„ˆë¬´ ê·¹ë‹¨ì ì¸ ê°’)
            for col in numeric_columns:
                if col in df_cleaned.columns:
                    q99 = df_cleaned[col].quantile(0.99)
                    q01 = df_cleaned[col].quantile(0.01)
                    df_cleaned[col] = df_cleaned[col].clip(lower=q01, upper=q99)

            logger.info(f"âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {len(df)} â†’ {len(df_cleaned)}ê°œ")
            return df_cleaned

        except Exception as e:
            logger.warning(f"âš ï¸ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return df

    def _create_metadata(self, df: pd.DataFrame) -> Dict:
        """ë©”íƒ€ë°ì´í„° ìƒì„±"""
        return {
            'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_stocks': len(df),
            'data_source': 'naver_finance_enhanced_60day_trend',
            'description': 'Enhanced ì „ì²´ í•œêµ­ ì£¼ì‹ 60ì¼ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë°ì´í„°',
            'version': '2.0',
            'columns_count': len(df.columns),
            'successful_scrapes': len(df[df['total_days'] > 0]),
            'failed_scrapes': len(df[df['total_days'] == 0]),
            'average_data_days': df['total_days'].mean(),
            'config_used': asdict(self.config)
        }

    def _create_summary_statistics(self, df: pd.DataFrame) -> Dict:
        """í†µê³„ ìš”ì•½ ìƒì„±"""
        try:
            return {
                'summary_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_stocks': len(df),

                # ê¸°ê´€ í†µê³„
                'inst_net_buy_20d_mean': df['institutional_net_buy_20d'].mean(),
                'inst_net_buy_20d_median': df['institutional_net_buy_20d'].median(),
                'inst_ratio_20d_mean': df['institutional_ratio_20d'].mean(),
                'inst_ratio_20d_median': df['institutional_ratio_20d'].median(),

                # ì™¸êµ­ì¸ í†µê³„
                'foreign_net_buy_20d_mean': df['foreign_net_buy_20d'].mean(),
                'foreign_net_buy_20d_median': df['foreign_net_buy_20d'].median(),
                'foreign_ratio_20d_mean': df['foreign_ratio_20d'].mean(),
                'foreign_ratio_20d_median': df['foreign_ratio_20d'].median(),

                # ìˆ˜ê¸‰ ì§€ìˆ˜ í†µê³„
                'supply_demand_index_mean': df['supply_demand_index'].mean(),
                'supply_demand_index_median': df['supply_demand_index'].median(),
                'supply_demand_index_std': df['supply_demand_index'].std(),

                # ë§¤ì§‘ ì‹ í˜¸ í†µê³„
                'strong_accumulation_count': df['strong_accumulation'].sum(),
                'accumulation_signal_count': df['accumulation_signal'].sum(),
                'strong_accumulation_ratio': df['strong_accumulation'].sum() / len(df) * 100,

                # íŠ¸ë Œë“œ ë¶„í¬
                'inst_buying_count': len(df[df['institutional_trend'].str.contains('buying', na=False)]),
                'foreign_buying_count': len(df[df['foreign_trend'].str.contains('buying', na=False)]),

                # ê³ ìœ„í—˜ ì¢…ëª©
                'high_risk_count': len(df[df['risk_level'] == 'ë†’ìŒ']),
                'high_momentum_count': len(df[df['momentum_score'] > 50])
            }

        except Exception as e:
            logger.warning(f"âš ï¸ í†µê³„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'summary_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'error': str(e)}

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Enhanced í•œêµ­ ì£¼ì‹ ì „ì²´ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘...")

    # ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§• (í•„ìš”ì‹œ)
    config = TrendConfig(
        strong_buy_inst=2500000,    # ê¸°ê´€ ê°•ë§¤ìˆ˜ ê¸°ì¤€ì„ 2.5ë°±ë§Œì£¼ë¡œ ì¡°ì •
        strong_buy_foreign=4000000, # ì™¸êµ­ì¸ ê°•ë§¤ìˆ˜ ê¸°ì¤€ì„ 4ë°±ë§Œì£¼ë¡œ ì¡°ì •
        high_ratio_inst=6.0,        # ê¸°ê´€ ê³ ë¹„ìœ¨ ê¸°ì¤€ì„ 6%ë¡œ ì¡°ì •
        high_ratio_foreign=10.0     # ì™¸êµ­ì¸ ê³ ë¹„ìœ¨ ê¸°ì¤€ì„ 10%ë¡œ ì¡°ì •
    )

    # Enhanced ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = EnhancedKoreanInstitutionalTrendAnalyzer(config=config)

    # ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë©€í‹°ìŠ¤ë ˆë”© ì‚¬ìš©)
    df = analyzer.download_all_institutional_data(
        max_stocks=None,        # ì „ì²´ ì¢…ëª© (í…ŒìŠ¤íŠ¸ì‹œ 50ìœ¼ë¡œ ì„¤ì •)
        max_workers=8,          # ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
        save_interval=100       # 100ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
    )

    if not df.empty:
        # ë°ì´í„° ì €ì¥
        if analyzer.save_institutional_data(df):
            print(f"\nğŸ¯ Enhanced ì „ì²´ ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤ íŠ¸ë Œë“œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ!")
            print(f"ğŸ“Š ì´ {len(df)}ê°œ ì¢…ëª©")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {analyzer.all_institutional_csv_path}")

            # Enhanced ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
            print(f"\nğŸ“‹ Enhanced ìƒ˜í”Œ ë°ì´í„°:")
            sample_cols = [
                'ticker', 'institutional_net_buy_20d', 'foreign_net_buy_20d',
                'institutional_ratio_20d', 'foreign_ratio_20d',
                'supply_demand_stage', 'accumulation_intensity',
                'momentum_score', 'risk_level'
            ]
            available_cols = [col for col in sample_cols if col in df.columns]
            print(df[available_cols].head(10))

            # Enhanced í†µê³„ ì •ë³´
            print(f"\nğŸ“Š Enhanced í†µê³„ ì •ë³´:")
            print(f"   ê¸°ê´€ 20ì¼ ìˆœë§¤ìˆ˜ í‰ê· : {df['institutional_net_buy_20d'].mean():,.0f}")
            print(f"   ì™¸êµ­ì¸ 20ì¼ ìˆœë§¤ìˆ˜ í‰ê· : {df['foreign_net_buy_20d'].mean():,.0f}")
            print(f"   ê¸°ê´€ 20ì¼ ë¹„ìœ¨ í‰ê· : {df['institutional_ratio_20d'].mean():.2f}%")
            print(f"   ì™¸êµ­ì¸ 20ì¼ ë¹„ìœ¨ í‰ê· : {df['foreign_ratio_20d'].mean():.2f}%")
            print(f"   ìˆ˜ê¸‰ ì§€ìˆ˜ í‰ê· : {df['supply_demand_index'].mean():.1f}")
            if 'momentum_score' in df.columns:
                print(f"   ëª¨ë©˜í…€ ì ìˆ˜ í‰ê· : {df['momentum_score'].mean():.1f}")
            if 'consistency_score' in df.columns:
                print(f"   ì¼ê´€ì„± ì ìˆ˜ í‰ê· : {df['consistency_score'].mean():.1f}")

            # Enhanced íŠ¸ë Œë“œ ë¶„ì„
            print(f"\nğŸ“ˆ Enhanced íŠ¸ë Œë“œ ë¶„ì„:")
            inst_trends = df['institutional_trend'].value_counts()
            foreign_trends = df['foreign_trend'].value_counts()
            print(f"   ê¸°ê´€ íŠ¸ë Œë“œ: {dict(inst_trends)}")
            print(f"   ì™¸êµ­ì¸ íŠ¸ë Œë“œ: {dict(foreign_trends)}")

            if 'risk_level' in df.columns:
                risk_levels = df['risk_level'].value_counts()
                print(f"   ë¦¬ìŠ¤í¬ ë ˆë²¨: {dict(risk_levels)}")

            # ê°•í•œ ë§¤ì§‘ ì¢…ëª© (Enhanced)
            strong_accumulation = df[df['strong_accumulation'] == 1]
            if not strong_accumulation.empty:
                print(f"\nğŸ”¥ ê°•í•œ ë§¤ì§‘ ì‹ í˜¸ ì¢…ëª© ({len(strong_accumulation)}ê°œ):")
                display_cols = [
                    'ticker', 'institutional_net_buy_20d', 'foreign_net_buy_20d',
                    'institutional_ratio_20d', 'foreign_ratio_20d',
                    'supply_demand_stage', 'accumulation_intensity'
                ]
                if 'momentum_score' in strong_accumulation.columns:
                    display_cols.append('momentum_score')
                print(strong_accumulation[display_cols])

            # ê³ ìœ„í—˜ ê³ ìˆ˜ìµ ì¢…ëª©
            if 'risk_level' in df.columns and 'momentum_score' in df.columns:
                high_risk_high_momentum = df[
                    (df['risk_level'] == 'ë†’ìŒ') &
                    (df['momentum_score'] > 30) &
                    (df['supply_demand_index'] > 70)
                ]
                if not high_risk_high_momentum.empty:
                    print(f"\nâš¡ ê³ ìœ„í—˜ ê³ ëª¨ë©˜í…€ ì¢…ëª© ({len(high_risk_high_momentum)}ê°œ):")
                    print(high_risk_high_momentum[['ticker', 'momentum_score', 'supply_demand_index', 'risk_level', 'trend_strength']])

            # ì¼ê´€ì„± ë†’ì€ ë§¤ì§‘ ì¢…ëª©
            if 'consistency_score' in df.columns:
                consistent_accumulation = df[
                    (df['consistency_score'] > 70) &
                    (df['accumulation_signal'] == 1)
                ]
                if not consistent_accumulation.empty:
                    print(f"\nğŸ¯ ì¼ê´€ì„± ë†’ì€ ë§¤ì§‘ ì¢…ëª© ({len(consistent_accumulation)}ê°œ):")
                    print(consistent_accumulation[['ticker', 'consistency_score', 'accumulation_intensity', 'supply_demand_stage']].head())

        else:
            print(f"\nâŒ Enhanced ê¸°ê´€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨!")
    else:
        print(f"\nâŒ Enhanced ê¸°ê´€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨!")

if __name__ == "__main__":
    main()