"""
ğŸ¤– LLM ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ (Perplexity + Gemini)
ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ê³¼ ê³ ë„í™”ëœ AI ë¶„ì„ì„ ê²°í•©í•˜ì—¬ ì¢…ëª©ë³„ í˜¸ì¬ ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.
"""

import os
import json
import re
import asyncio
import httpx
import google.generativeai as genai
from typing import List, Dict, Optional
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API ìƒíƒœ ì¶”ì  (Rate Limit ê´€ë¦¬)
API_STATUS = {
    'perplexity': {'available': True, 'last_error': None, 'error_count': 0},
    'gemini': {'available': True, 'last_error': None, 'error_count': 0},
    'openai': {'available': True, 'last_error': None, 'error_count': 0}
}

def reset_api_status():
    """API ìƒíƒœ ì´ˆê¸°í™” (ì„¸ì…˜ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global API_STATUS
    for key in API_STATUS:
        API_STATUS[key] = {'available': True, 'last_error': None, 'error_count': 0}

class PerplexityClient:
    """Perplexity Sonar APIë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê²€ìƒ‰"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("PERPLEXITY_API_KEY")
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.model = "sonar"
        
    async def search_stock_news(self, stock_name: str) -> Dict:
        """ìµœê·¼ 24ì‹œê°„ ì´ë‚´ì˜ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½"""
        global API_STATUS

        if not self.api_key:
            return {"news_summary": "", "citations": [], "error": "No API Key"}

        if not API_STATUS['perplexity']['available']:
            return {"news_summary": "", "citations": [], "error": f"Rate Limited: {API_STATUS['perplexity']['last_error']}"}
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        query = f"'{stock_name}' ì¢…ëª©ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ì™€ ì‹œì¥ ë™í–¥ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”. 1. ìµœê·¼ 24ì‹œê°„ ì´ë‚´ì˜ ì£¼ìš” ë‰´ìŠ¤(í˜¸ì¬/ì•…ì¬), 2. ì‹¤ì /ìˆ˜ì£¼/ê³„ì•½ ì •ë³´, 3. ê´€ë ¨ í…Œë§ˆ ë° ì‚°ì—… ë™í–¥ì„ í¬í•¨í•´ ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ ë¦¬ì„œì¹˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": query}
            ],
            "temperature": 0.2,
            "max_tokens": 1024,
            "return_citations": True,
            "search_recency_filter": "day"
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(self.base_url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                
                return {
                    "news_summary": data["choices"][0]["message"]["content"],
                    "citations": data.get("citations", []),
                    "source": "perplexity"
                }
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] Perplexity Search Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg:
                API_STATUS['perplexity']['available'] = False
                API_STATUS['perplexity']['last_error'] = 'Rate Limit'
                API_STATUS['perplexity']['error_count'] += 1
                print("[WARN] Perplexity Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"news_summary": "", "citations": [], "error": str(e)}

class OpenAIAnalyzer:
    """OpenAI GPTë¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ (Gemini Fallback)"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if self.api_key:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=self.api_key)
            self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini") # ê°€ì„±ë¹„ ëª¨ë¸ ê¸°ë³¸ê°’
        else:
            self.client = None
            
    async def analyze_news(self, stock_name: str, perplexity_news: str, traditional_news: List[Dict] = None) -> Dict:
        global API_STATUS

        if not self.client:
            return {"score": 0, "reason": "No OpenAI Client", "themes": []}

        if not API_STATUS['openai']['available']:
            return {"score": 0, "reason": f"Rate Limited: {API_STATUS['openai']['last_error']}", "themes": []}
            
        trad_text = ""
        if traditional_news:
            for i, item in enumerate(traditional_news[:5], 1):
                trad_text += f"[{i}] {item.get('title')} - {item.get('summary', '')[:100]}\n"
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{stock_name}' ì¢…ëª©ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ê°•ë„ì™€ í…Œë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        [Perplexity ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼]
        {perplexity_news}

        [ê¸°ì¡´ ë‰´ìŠ¤ ì •ë³´]
        {trad_text}

        ìœ„ ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ëŠ” JSON ê°ì²´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. 
        - score: 0~3ì  (3:í™•ì‹¤í•œ í˜¸ì¬/ìˆ˜ì£¼/ì‹¤ì , 2:ê¸ì • ê¸°ëŒ€ê°, 1:ì¤‘ë¦½, 0:ì•…ì¬/ë¬´ì†Œì‹)
        - reason: ë¶„ì„ í•µì‹¬ ì´ìœ  (í•œ ë¬¸ì¥)
        - themes: í•µì‹¬ íˆ¬ì í…Œë§ˆ 1~3ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)

        JSON Format: {{"score": 2, "reason": "...", "themes": ["...", "..."]}}
        """
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful financial analyst. Respond only in JSON."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] OpenAI Analysis Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg:
                API_STATUS['openai']['available'] = False
                API_STATUS['openai']['last_error'] = 'Rate Limit'
                API_STATUS['openai']['error_count'] += 1
                print("[WARN] OpenAI Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"score": 0, "reason": f"OpenAI Error: {e}", "themes": []}

class GeminiAnalyzer:
    """Geminië¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ ë° ì ìˆ˜ ì‚°ì¶œ"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if self.api_key:
            genai.configure(api_key=self.api_key)
            model_name = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
            self.model = genai.GenerativeModel(model_name)
        else:
            self.model = None
            
    async def analyze_news(self, stock_name: str, perplexity_news: str, traditional_news: List[Dict] = None) -> Dict:
        """Perplexity ê²°ê³¼ì™€ ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì ìˆ˜í™”"""
        global API_STATUS

        if not self.model:
            return {"score": 0, "reason": "No Gemini Model", "themes": []}

        if not API_STATUS['gemini']['available']:
            return {"score": 0, "reason": f"Rate Limited: {API_STATUS['gemini']['last_error']}", "themes": []}
            
        trad_text = ""
        if traditional_news:
            for i, item in enumerate(traditional_news[:5], 1):
                trad_text += f"[{i}] {item.get('title')} - {item.get('summary', '')[:100]}\n"
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{stock_name}' ì¢…ëª©ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ê°•ë„ì™€ í…Œë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        [Perplexity ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼]
        {perplexity_news}

        [ê¸°ì¡´ ë‰´ìŠ¤ ì •ë³´]
        {trad_text}

        ìœ„ ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ëŠ” JSON ê°ì²´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. 
        - score: 0~3ì  (3:í™•ì‹¤í•œ í˜¸ì¬/ìˆ˜ì£¼/ì‹¤ì , 2:ê¸ì • ê¸°ëŒ€ê°, 1:ì¤‘ë¦½, 0:ì•…ì¬/ë¬´ì†Œì‹)
        - reason: ë¶„ì„ í•µì‹¬ ì´ìœ  (í•œ ë¬¸ì¥)
        - themes: í•µì‹¬ íˆ¬ì í…Œë§ˆ 1~3ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)

        JSON Format: {{"score": 2, "reason": "...", "themes": ["...", "..."]}}
        """
        
        try:
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            text = response.text.strip()
            # JSON íŒŒì‹± ë° ì˜ˆì™¸ ì²˜ë¦¬
            try:
                data = json.loads(text)
                if isinstance(data, list) and len(data) > 0:
                    data = data[0]
                return data if isinstance(data, dict) else {"score": 0, "reason": "Invalid JSON format", "themes": []}
            except json.JSONDecodeError:
                # í…ìŠ¤íŠ¸ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
                match = re.search(r"\{.*\}", text, re.DOTALL)
                if match:
                    return json.loads(match.group())
                return {"score": 0, "reason": f"JSON Decode Failed: {text[:50]}", "themes": []}
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] Gemini Analysis Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg or 'resource' in error_msg:
                API_STATUS['gemini']['available'] = False
                API_STATUS['gemini']['last_error'] = 'Rate Limit'
                API_STATUS['gemini']['error_count'] += 1
                print("[WARN] Gemini Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"score": 0, "reason": f"Analysis Error: {e}", "themes": []}

class LLMAnalyzer:
    """í†µí•© ë‰´ìŠ¤ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Perplexity -> Gemini -> OpenAI -> Fallback)

    3ì¤‘ API í´ë°± ì‹œìŠ¤í…œ:
    1. Perplexity (ì‹¤ì‹œê°„ ê²€ìƒ‰) - Rate Limit ì‹œ ìŠ¤í‚µ
    2. Gemini (ë¶„ì„) - Rate Limit ì‹œ OpenAIë¡œ í´ë°±
    3. OpenAI (ë¶„ì„) - Rate Limit ì‹œ í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í´ë°±
    """

    def __init__(self):
        self.perplexity = PerplexityClient()
        self.gemini = GeminiAnalyzer()
        self.openai = OpenAIAnalyzer()
        # model ì†ì„± ì¶”ê°€ (generator.py í˜¸í™˜ì„±)
        self.model = self.gemini.model or self.openai.client

    def get_api_status(self) -> Dict:
        """í˜„ì¬ API ìƒíƒœ ë°˜í™˜"""
        return {
            'perplexity': 'active' if API_STATUS['perplexity']['available'] else 'rate_limited',
            'gemini': 'active' if API_STATUS['gemini']['available'] else 'rate_limited',
            'openai': 'active' if API_STATUS['openai']['available'] else 'rate_limited',
            'errors': {k: v['error_count'] for k, v in API_STATUS.items()}
        }

    async def analyze_news_sentiment(self, stock_name: str, news_items: List[Dict] = None) -> Dict:
        """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ í†µí•© í”„ë¡œì„¸ìŠ¤ (3ì¤‘ í´ë°± ì‹œìŠ¤í…œ)"""
        news_summary = ""
        citations = []
        analysis_source = "none"

        # 1. Perplexity ê²€ìƒ‰ (ì‹¤ì‹œê°„ ì •ë³´) - Rate Limit ì‹œ ìŠ¤í‚µ
        if API_STATUS['perplexity']['available']:
            p_res = await self.perplexity.search_stock_news(stock_name)
            news_summary = p_res.get("news_summary", "")
            citations = p_res.get("citations", [])

            # Rate Limit ë°©ì§€
            if news_summary:
                await asyncio.sleep(1)
                analysis_source = "perplexity"
        else:
            print(f"[SKIP] Perplexity Rate Limited - {stock_name}")

        # ë¶„ì„ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ ë¥¸ ì¢…ë£Œ
        if not news_summary and not news_items:
            return self._keyword_fallback(stock_name, [])

        analysis = None

        # 2. Main Analysis (Gemini Attempt) - Rate Limit ì‹œ ìŠ¤í‚µ
        if API_STATUS['gemini']['available']:
            analysis = await self.gemini.analyze_news(stock_name, news_summary, news_items)
            if analysis.get("score") > 0 or "Error" not in analysis.get("reason", ""):
                analysis["source"] = f"{analysis_source}+gemini" if analysis_source else "gemini_only"
            else:
                analysis = None  # Gemini ì‹¤íŒ¨ - OpenAIë¡œ í´ë°±
        else:
            print(f"[SKIP] Gemini Rate Limited - {stock_name}")

        # 3. Fallback Analysis (OpenAI Attempt) - Rate Limit ì‹œ ìŠ¤í‚µ
        if analysis is None and API_STATUS['openai']['available']:
            print(f"[FALLBACK] Gemini Failed for {stock_name}, trying OpenAI...")
            analysis = await self.openai.analyze_news(stock_name, news_summary, news_items)
            if analysis.get("score") > 0 or "Error" not in analysis.get("reason", ""):
                analysis["source"] = f"{analysis_source}+openai" if analysis_source else "openai_only"
            else:
                analysis = None  # OpenAIë„ ì‹¤íŒ¨
        elif analysis is None:
            print(f"[SKIP] OpenAI Rate Limited - {stock_name}")

        # 4. Final Fallback (Keyword) - ëª¨ë“  LLM ì‹¤íŒ¨ ì‹œ
        if analysis is None or (analysis.get("score") == 0 and ("Error" in analysis.get("reason", "") or "Rate" in analysis.get("reason", ""))):
            print(f"[FALLBACK] All LLMs failed for {stock_name}, using keywords...")
            return self._keyword_fallback(stock_name, news_items)

        # ì„±ê³µ ì‹œ ê²°ê³¼ ë°˜í™˜
        if not isinstance(analysis, dict):
            return self._keyword_fallback(stock_name, news_items)

        analysis["citations"] = citations
        analysis["api_status"] = self.get_api_status()
        return analysis

    def _keyword_fallback(self, stock_name: str, news_items: List[Dict]) -> Dict:
        """API ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ ë¶„ì„"""
        score = 0
        reason = "No news data available"
        themes = []
        
        if news_items:
            positive = ["ìˆ˜ì£¼", "ê³„ì•½", "í‘ì", "ì„±ê³µ", "ê¸‰ë“±", "ì–´ë‹", "FDA", "M&A", "íŠ¹í—ˆ", "ê³µê¸‰", "ê°œë°œ"]
            negative = ["ì˜ì—…ì •ì§€", "ë°°ì„", "íš¡ë ¹", "ì ì", "ìƒì¥íì§€", "ê¸‰ë½", "ìˆ˜ì‚¬", "ë¶ˆì„±ì‹¤"]
            
            all_text = " ".join([n.get("title", "") + n.get("summary", "") for n in news_items])
            
            if any(w in all_text for w in negative):
                score = 0
                reason = "ë¶€ì •ì  í‚¤ì›Œë“œ ê°ì§€ë¨"
            else:
                matches = [w for w in positive if w in all_text]
                # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìˆ˜ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬ (ìµœëŒ€ 2ì  - LLMë³´ë‹¤ëŠ” ë³´ìˆ˜ì )
                if len(matches) >= 2:
                    score = 2
                elif len(matches) == 1:
                    score = 1
                else:
                    score = 0
                    
                reason = f"í‚¤ì›Œë“œ ë¶„ì„ ({', '.join(matches[:3])})" if matches else "í˜¸ì¬ í‚¤ì›Œë“œ ì—†ìŒ"
            
        return {
            "score": score,
            "reason": reason,
            "themes": themes,
            "source": "keyword_fallback"
        }

if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    async def test():
        analyzer = LLMAnalyzer()
        print("ğŸ” ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘: ì‚¼ì„±ì „ì")
        result = await analyzer.analyze_news_sentiment("ì‚¼ì„±ì „ì", [])
        print(json.dumps(result, indent=2, ensure_ascii=False))

    asyncio.run(test())
