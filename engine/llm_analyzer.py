"""
ğŸ¤– LLM ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ (Perplexity + Gemini + Claude + OpenAI)
ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ê³¼ ê³ ë„í™”ëœ AI ë¶„ì„ì„ ê²°í•©í•˜ì—¬ ì¢…ëª©ë³„ í˜¸ì¬ ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.
Claude AI ë…ë¦½ ì¢…ëª© ì„ ë³„ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

import os
import json
import re
import asyncio
import httpx
import google.generativeai as genai
from typing import List, Dict, Optional
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API ìƒíƒœ ì¶”ì  (Rate Limit ê´€ë¦¬)
API_STATUS = {
    'perplexity': {'available': True, 'last_error': None, 'error_count': 0},
    'gemini': {'available': True, 'last_error': None, 'error_count': 0},
    'claude': {'available': True, 'last_error': None, 'error_count': 0},
    'openai': {'available': True, 'last_error': None, 'error_count': 0}
}

def reset_api_status():
    """API ìƒíƒœ ì´ˆê¸°í™” (ì„¸ì…˜ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global API_STATUS
    for key in API_STATUS:
        API_STATUS[key] = {'available': True, 'last_error': None, 'error_count': 0}

class PerplexityClient:
    """Perplexity Sonar APIë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê²€ìƒ‰"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("PERPLEXITY_API_KEY")
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.model = "sonar"
        
    async def search_stock_news(self, stock_name: str) -> Dict:
        """ìµœê·¼ 24ì‹œê°„ ì´ë‚´ì˜ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½"""
        global API_STATUS

        if not self.api_key:
            return {"news_summary": "", "citations": [], "error": "No API Key"}

        if not API_STATUS['perplexity']['available']:
            return {"news_summary": "", "citations": [], "error": f"Rate Limited: {API_STATUS['perplexity']['last_error']}"}
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        query = f"'{stock_name}' ì¢…ëª©ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ì™€ ì‹œì¥ ë™í–¥ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”. 1. ìµœê·¼ 24ì‹œê°„ ì´ë‚´ì˜ ì£¼ìš” ë‰´ìŠ¤(í˜¸ì¬/ì•…ì¬), 2. ì‹¤ì /ìˆ˜ì£¼/ê³„ì•½ ì •ë³´, 3. ê´€ë ¨ í…Œë§ˆ ë° ì‚°ì—… ë™í–¥ì„ í¬í•¨í•´ ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ ë¦¬ì„œì¹˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": query}
            ],
            "temperature": 0.2,
            "max_tokens": 1024,
            "return_citations": True,
            "search_recency_filter": "day"
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(self.base_url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                
                return {
                    "news_summary": data["choices"][0]["message"]["content"],
                    "citations": data.get("citations", []),
                    "source": "perplexity"
                }
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] Perplexity Search Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg:
                API_STATUS['perplexity']['available'] = False
                API_STATUS['perplexity']['last_error'] = 'Rate Limit'
                API_STATUS['perplexity']['error_count'] += 1
                print("[WARN] Perplexity Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"news_summary": "", "citations": [], "error": str(e)}

class OpenAIAnalyzer:
    """OpenAI GPTë¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ (Gemini Fallback)"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if self.api_key:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=self.api_key)
            self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini") # ê°€ì„±ë¹„ ëª¨ë¸ ê¸°ë³¸ê°’
        else:
            self.client = None
            
    async def analyze_news(self, stock_name: str, perplexity_news: str, traditional_news: List[Dict] = None, dart_text: str = "") -> Dict:
        global API_STATUS

        if not self.client:
            return {"score": 0, "reason": "No OpenAI Client", "themes": []}

        if not API_STATUS['openai']['available']:
            return {"score": 0, "reason": f"Rate Limited: {API_STATUS['openai']['last_error']}", "themes": []}

        trad_text = ""
        if traditional_news:
            for i, item in enumerate(traditional_news[:5], 1):
                trad_text += f"[{i}] {item.get('title')} - {item.get('summary', '')[:100]}\n"

        dart_section = ""
        if dart_text:
            dart_section = f"""
        [ê³µì‹ ê³µì‹œ ì •ë³´ (DART ì „ìê³µì‹œ)]
        {dart_text}
        """

        prompt = f"""
        ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{stock_name}' ì¢…ëª©ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ê°•ë„ì™€ í…Œë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        [Perplexity ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼]
        {perplexity_news}

        [ê¸°ì¡´ ë‰´ìŠ¤ ì •ë³´]
        {trad_text}
        {dart_section}
        ìœ„ ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ëŠ” JSON ê°ì²´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - score: 0~3ì  (3:í™•ì‹¤í•œ í˜¸ì¬/ìˆ˜ì£¼/ì‹¤ì , 2:ê¸ì • ê¸°ëŒ€ê°, 1:ì¤‘ë¦½, 0:ì•…ì¬/ë¬´ì†Œì‹)
        - reason: ë¶„ì„ í•µì‹¬ ì´ìœ  (í•œ ë¬¸ì¥)
        - themes: í•µì‹¬ íˆ¬ì í…Œë§ˆ 1~3ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
        * ê³µì‹ ê³µì‹œ(DART)ê°€ ìˆìœ¼ë©´ ë‰´ìŠ¤ë³´ë‹¤ ë†’ì€ ì‹ ë¢°ë„ë¡œ ë°˜ì˜í•˜ì„¸ìš” (ìì‚¬ì£¼ì·¨ë“, ë¬´ìƒì¦ì, ëŒ€ê·œëª¨ìˆ˜ì£¼ = 3ì  ìˆ˜ì¤€)

        JSON Format: {{"score": 2, "reason": "...", "themes": ["...", "..."]}}
        """
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful financial analyst. Respond only in JSON."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] OpenAI Analysis Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg:
                API_STATUS['openai']['available'] = False
                API_STATUS['openai']['last_error'] = 'Rate Limit'
                API_STATUS['openai']['error_count'] += 1
                print("[WARN] OpenAI Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"score": 0, "reason": f"OpenAI Error: {e}", "themes": []}

class GeminiAnalyzer:
    """Geminië¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ ë° ì ìˆ˜ ì‚°ì¶œ"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if self.api_key:
            genai.configure(api_key=self.api_key)
            model_name = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
            self.model = genai.GenerativeModel(model_name)
        else:
            self.model = None
            
    async def analyze_news(self, stock_name: str, perplexity_news: str, traditional_news: List[Dict] = None, dart_text: str = "") -> Dict:
        """Perplexity ê²°ê³¼ì™€ ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì ìˆ˜í™”"""
        global API_STATUS

        if not self.model:
            return {"score": 0, "reason": "No Gemini Model", "themes": []}

        if not API_STATUS['gemini']['available']:
            return {"score": 0, "reason": f"Rate Limited: {API_STATUS['gemini']['last_error']}", "themes": []}

        trad_text = ""
        if traditional_news:
            for i, item in enumerate(traditional_news[:5], 1):
                trad_text += f"[{i}] {item.get('title')} - {item.get('summary', '')[:100]}\n"

        dart_section = ""
        if dart_text:
            dart_section = f"""
        [ê³µì‹ ê³µì‹œ ì •ë³´ (DART ì „ìê³µì‹œ)]
        {dart_text}
        """

        prompt = f"""
        ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{stock_name}' ì¢…ëª©ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ê°•ë„ì™€ í…Œë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        [Perplexity ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼]
        {perplexity_news}

        [ê¸°ì¡´ ë‰´ìŠ¤ ì •ë³´]
        {trad_text}
        {dart_section}
        ìœ„ ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ëŠ” JSON ê°ì²´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - score: 0~3ì  (3:í™•ì‹¤í•œ í˜¸ì¬/ìˆ˜ì£¼/ì‹¤ì , 2:ê¸ì • ê¸°ëŒ€ê°, 1:ì¤‘ë¦½, 0:ì•…ì¬/ë¬´ì†Œì‹)
        - reason: ë¶„ì„ í•µì‹¬ ì´ìœ  (í•œ ë¬¸ì¥)
        - themes: í•µì‹¬ íˆ¬ì í…Œë§ˆ 1~3ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
        * ê³µì‹ ê³µì‹œ(DART)ê°€ ìˆìœ¼ë©´ ë‰´ìŠ¤ë³´ë‹¤ ë†’ì€ ì‹ ë¢°ë„ë¡œ ë°˜ì˜í•˜ì„¸ìš” (ìì‚¬ì£¼ì·¨ë“, ë¬´ìƒì¦ì, ëŒ€ê·œëª¨ìˆ˜ì£¼ = 3ì  ìˆ˜ì¤€)

        JSON Format: {{"score": 2, "reason": "...", "themes": ["...", "..."]}}
        """
        
        try:
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            text = response.text.strip()
            # JSON íŒŒì‹± ë° ì˜ˆì™¸ ì²˜ë¦¬
            try:
                data = json.loads(text)
                if isinstance(data, list) and len(data) > 0:
                    data = data[0]
                return data if isinstance(data, dict) else {"score": 0, "reason": "Invalid JSON format", "themes": []}
            except json.JSONDecodeError:
                # í…ìŠ¤íŠ¸ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
                match = re.search(r"\{.*\}", text, re.DOTALL)
                if match:
                    return json.loads(match.group())
                return {"score": 0, "reason": f"JSON Decode Failed: {text[:50]}", "themes": []}
        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] Gemini Analysis Failed: {e}")

            # Rate Limit ê°ì§€
            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg or 'resource' in error_msg:
                API_STATUS['gemini']['available'] = False
                API_STATUS['gemini']['last_error'] = 'Rate Limit'
                API_STATUS['gemini']['error_count'] += 1
                print("[WARN] Gemini Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"score": 0, "reason": f"Analysis Error: {e}", "themes": []}

class ClaudeAnalyzer:
    """Claude Haiku 4.5ë¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ (Gemini Fallback)"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        self.model_name = "claude-haiku-4-5-20251001"
        if self.api_key:
            import anthropic
            self.client = anthropic.AsyncAnthropic(api_key=self.api_key)
        else:
            self.client = None

    async def analyze_news(self, stock_name: str, perplexity_news: str, traditional_news: List[Dict] = None, dart_text: str = "") -> Dict:
        """Perplexity ê²°ê³¼ì™€ ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì ìˆ˜í™”"""
        global API_STATUS

        if not self.client:
            return {"score": 0, "reason": "No Claude Client", "themes": []}

        if not API_STATUS['claude']['available']:
            return {"score": 0, "reason": f"Rate Limited: {API_STATUS['claude']['last_error']}", "themes": []}

        trad_text = ""
        if traditional_news:
            for i, item in enumerate(traditional_news[:5], 1):
                trad_text += f"[{i}] {item.get('title')} - {item.get('summary', '')[:100]}\n"

        dart_section = ""
        if dart_text:
            dart_section = f"""
[ê³µì‹ ê³µì‹œ ì •ë³´ (DART ì „ìê³µì‹œ)]
{dart_text}
"""

        prompt = f"""ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{stock_name}' ì¢…ëª©ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸ì¬ ê°•ë„ì™€ í…Œë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

[Perplexity ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼]
{perplexity_news}

[ê¸°ì¡´ ë‰´ìŠ¤ ì •ë³´]
{trad_text}
{dart_section}
ìœ„ ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ëŠ” JSON ê°ì²´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- score: 0~3ì  (3:í™•ì‹¤í•œ í˜¸ì¬/ìˆ˜ì£¼/ì‹¤ì , 2:ê¸ì • ê¸°ëŒ€ê°, 1:ì¤‘ë¦½, 0:ì•…ì¬/ë¬´ì†Œì‹)
- reason: ë¶„ì„ í•µì‹¬ ì´ìœ  (í•œ ë¬¸ì¥)
- themes: í•µì‹¬ íˆ¬ì í…Œë§ˆ 1~3ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
* ê³µì‹ ê³µì‹œ(DART)ê°€ ìˆìœ¼ë©´ ë‰´ìŠ¤ë³´ë‹¤ ë†’ì€ ì‹ ë¢°ë„ë¡œ ë°˜ì˜í•˜ì„¸ìš” (ìì‚¬ì£¼ì·¨ë“, ë¬´ìƒì¦ì, ëŒ€ê·œëª¨ìˆ˜ì£¼ = 3ì  ìˆ˜ì¤€)

JSON Format: {{"score": 2, "reason": "...", "themes": ["...", "..."]}}"""

        try:
            response = await self.client.messages.create(
                model=self.model_name,
                max_tokens=512,
                system="You are a helpful financial analyst. Respond only in valid JSON.",
                messages=[{"role": "user", "content": prompt}],
            )
            content = response.content[0].text.strip()

            try:
                return json.loads(content)
            except json.JSONDecodeError:
                match = re.search(r"\{.*\}", content, re.DOTALL)
                if match:
                    return json.loads(match.group())
                return {"score": 0, "reason": f"JSON Decode Failed: {content[:50]}", "themes": []}

        except Exception as e:
            error_msg = str(e).lower()
            print(f"[ERROR] Claude Analysis Failed: {e}")

            if 'rate' in error_msg or 'limit' in error_msg or '429' in error_msg or 'quota' in error_msg or 'overloaded' in error_msg:
                API_STATUS['claude']['available'] = False
                API_STATUS['claude']['last_error'] = 'Rate Limit'
                API_STATUS['claude']['error_count'] += 1
                print("[WARN] Claude Rate Limit - ì„ì‹œ ë¹„í™œì„±í™”")

            return {"score": 0, "reason": f"Claude Error: {e}", "themes": []}


class LLMAnalyzer:
    """í†µí•© ë‰´ìŠ¤ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Perplexity -> Gemini -> Claude -> OpenAI -> Fallback)

    4ì¤‘ API í´ë°± ì‹œìŠ¤í…œ:
    1. Perplexity (ì‹¤ì‹œê°„ ê²€ìƒ‰) - Rate Limit ì‹œ ìŠ¤í‚µ
    2. Gemini (ë¶„ì„) - Rate Limit ì‹œ Claudeë¡œ í´ë°±
    3. Claude (ë¶„ì„) - Rate Limit ì‹œ OpenAIë¡œ í´ë°±
    4. OpenAI (ë¶„ì„) - Rate Limit ì‹œ í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í´ë°±
    """

    def __init__(self):
        self.perplexity = PerplexityClient()
        self.gemini = GeminiAnalyzer()
        self.claude = ClaudeAnalyzer()
        self.openai = OpenAIAnalyzer()
        # model ì†ì„± ì¶”ê°€ (generator.py í˜¸í™˜ì„±)
        self.model = self.gemini.model or self.claude.client or self.openai.client

    def get_api_status(self) -> Dict:
        """í˜„ì¬ API ìƒíƒœ ë°˜í™˜"""
        return {
            'perplexity': 'active' if API_STATUS['perplexity']['available'] else 'rate_limited',
            'gemini': 'active' if API_STATUS['gemini']['available'] else 'rate_limited',
            'claude': 'active' if API_STATUS['claude']['available'] else 'rate_limited',
            'openai': 'active' if API_STATUS['openai']['available'] else 'rate_limited',
            'errors': {k: v['error_count'] for k, v in API_STATUS.items()}
        }

    async def analyze_news_sentiment(self, stock_name: str, news_items: List[Dict] = None, dart_text: str = "") -> Dict:
        """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ í†µí•© í”„ë¡œì„¸ìŠ¤ (3ì¤‘ í´ë°± ì‹œìŠ¤í…œ) + DART ê³µì‹œ ì •ë³´"""
        news_summary = ""
        citations = []
        analysis_source = "none"

        # 1. Perplexity ê²€ìƒ‰ (ì‹¤ì‹œê°„ ì •ë³´) - Rate Limit ì‹œ ìŠ¤í‚µ
        if API_STATUS['perplexity']['available']:
            p_res = await self.perplexity.search_stock_news(stock_name)
            news_summary = p_res.get("news_summary", "")
            citations = p_res.get("citations", [])

            # Rate Limit ë°©ì§€
            if news_summary:
                await asyncio.sleep(1)
                analysis_source = "perplexity"
        else:
            print(f"[SKIP] Perplexity Rate Limited - {stock_name}")

        # ë¶„ì„ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ ë¥¸ ì¢…ë£Œ
        if not news_summary and not news_items:
            return self._keyword_fallback(stock_name, [])

        analysis = None

        # 2. Main Analysis (Gemini Attempt) - Rate Limit ì‹œ ìŠ¤í‚µ
        if API_STATUS['gemini']['available']:
            analysis = await self.gemini.analyze_news(stock_name, news_summary, news_items, dart_text)
            if analysis.get("score") > 0 or "Error" not in analysis.get("reason", ""):
                analysis["source"] = f"{analysis_source}+gemini" if analysis_source else "gemini_only"
            else:
                analysis = None  # Gemini ì‹¤íŒ¨ - OpenAIë¡œ í´ë°±
        else:
            print(f"[SKIP] Gemini Rate Limited - {stock_name}")

        # 2.5 Claude Fallback (Gemini ì‹¤íŒ¨ ì‹œ) - Rate Limit ì‹œ ìŠ¤í‚µ
        if analysis is None and API_STATUS['claude']['available']:
            print(f"[FALLBACK] Gemini Failed for {stock_name}, trying Claude...")
            analysis = await self.claude.analyze_news(stock_name, news_summary, news_items, dart_text)
            if analysis.get("score") > 0 or "Error" not in analysis.get("reason", ""):
                analysis["source"] = f"{analysis_source}+claude" if analysis_source else "claude_only"
            else:
                analysis = None  # Claudeë„ ì‹¤íŒ¨
        elif analysis is None and not API_STATUS['claude']['available']:
            print(f"[SKIP] Claude Rate Limited - {stock_name}")

        # 3. Fallback Analysis (OpenAI Attempt) - Rate Limit ì‹œ ìŠ¤í‚µ
        if analysis is None and API_STATUS['openai']['available']:
            print(f"[FALLBACK] Claude Failed for {stock_name}, trying OpenAI...")
            analysis = await self.openai.analyze_news(stock_name, news_summary, news_items, dart_text)
            if analysis.get("score") > 0 or "Error" not in analysis.get("reason", ""):
                analysis["source"] = f"{analysis_source}+openai" if analysis_source else "openai_only"
            else:
                analysis = None  # OpenAIë„ ì‹¤íŒ¨
        elif analysis is None:
            print(f"[SKIP] OpenAI Rate Limited - {stock_name}")

        # 4. Final Fallback (Keyword) - ëª¨ë“  LLM ì‹¤íŒ¨ ì‹œ
        if analysis is None or (analysis.get("score") == 0 and ("Error" in analysis.get("reason", "") or "Rate" in analysis.get("reason", ""))):
            print(f"[FALLBACK] All LLMs failed for {stock_name}, using keywords...")
            return self._keyword_fallback(stock_name, news_items)

        # ì„±ê³µ ì‹œ ê²°ê³¼ ë°˜í™˜
        if not isinstance(analysis, dict):
            return self._keyword_fallback(stock_name, news_items)

        analysis["citations"] = citations
        analysis["api_status"] = self.get_api_status()
        return analysis

    def _keyword_fallback(self, stock_name: str, news_items: List[Dict]) -> Dict:
        """API ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ ë¶„ì„"""
        score = 0
        reason = "No news data available"
        themes = []
        
        if news_items:
            positive = ["ìˆ˜ì£¼", "ê³„ì•½", "í‘ì", "ì„±ê³µ", "ê¸‰ë“±", "ì–´ë‹", "FDA", "M&A", "íŠ¹í—ˆ", "ê³µê¸‰", "ê°œë°œ"]
            negative = ["ì˜ì—…ì •ì§€", "ë°°ì„", "íš¡ë ¹", "ì ì", "ìƒì¥íì§€", "ê¸‰ë½", "ìˆ˜ì‚¬", "ë¶ˆì„±ì‹¤"]
            
            all_text = " ".join([n.get("title", "") + n.get("summary", "") for n in news_items])
            
            if any(w in all_text for w in negative):
                score = 0
                reason = "ë¶€ì •ì  í‚¤ì›Œë“œ ê°ì§€ë¨"
            else:
                matches = [w for w in positive if w in all_text]
                # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìˆ˜ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬ (ìµœëŒ€ 2ì  - LLMë³´ë‹¤ëŠ” ë³´ìˆ˜ì )
                if len(matches) >= 2:
                    score = 2
                elif len(matches) == 1:
                    score = 1
                else:
                    score = 0
                    
                reason = f"í‚¤ì›Œë“œ ë¶„ì„ ({', '.join(matches[:3])})" if matches else "í˜¸ì¬ í‚¤ì›Œë“œ ì—†ìŒ"
            
        return {
            "score": score,
            "reason": reason,
            "themes": themes,
            "source": "keyword_fallback"
        }

class ClaudeScreener:
    """Claude ê¸°ë°˜ ë…ë¦½ì  ì¢…ëª© ì„ ë³„ê¸°

    ì „ì²´ ì‹œê·¸ë„ ë°ì´í„°ë¥¼ ë°›ì•„ Claudeê°€ ë…ë¦½ì ìœ¼ë¡œ
    Top Picksë¥¼ ì„ ë³„í•˜ê³  ì¶”ì²œ ì´ìœ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        self.model_name = "claude-haiku-4-5-20251001"
        if self.api_key:
            import anthropic
            self.client = anthropic.AsyncAnthropic(api_key=self.api_key)
        else:
            self.client = None

    async def screen_candidates(self, signals_data: List[Dict]) -> Dict:
        """
        ì „ì²´ ì‹œê·¸ë„ ë°ì´í„°ë¥¼ ë°›ì•„ Claudeê°€ ë…ë¦½ì ìœ¼ë¡œ ì¢…ëª©ì„ ì„ ë³„í•©ë‹ˆë‹¤.

        Args:
            signals_data: Signal.to_dict() ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            { "picks": [...], "market_view": "...", "top_themes": [...] }
        """
        if not self.client:
            return {"picks": [], "error": "No Claude Client", "generated_at": datetime.now().isoformat()}

        if not signals_data:
            return {"picks": [], "error": "No signals to screen", "generated_at": datetime.now().isoformat()}

        candidates_text = self._build_candidates_summary(signals_data)

        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ì˜¤ëŠ˜ì˜ ì¢…ê°€ë² íŒ…(Closing Bet) ì‹œê·¸ë„ í›„ë³´ ì¢…ëª© {len(signals_data)}ê°œì˜ ë°ì´í„°ì…ë‹ˆë‹¤.

[í›„ë³´ ì¢…ëª© ë°ì´í„°]
{candidates_text}

ìœ„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì¢… Top 10~15 ì¢…ëª©ì„ ì„ ë³„í•´ì£¼ì„¸ìš”.

ì„ ë³„ ê¸°ì¤€:
1. ë‰´ìŠ¤/ì¬ë£Œì˜ ì§ˆì  ìˆ˜ì¤€ (ë‹¨ìˆœ í…Œë§ˆ vs ì‹¤ì /ìˆ˜ì£¼)
2. ìˆ˜ê¸‰ íë¦„ (ì™¸ì¸+ê¸°ê´€ ë™ì‹œ ë§¤ìˆ˜ ìš°ì„ )
3. ì°¨íŠ¸ ê¸°ìˆ ì  ìœ„ì¹˜ (ì‹ ê³ ê°€/ëŒíŒŒ/ì •ë°°ì—´)
4. ê±°ë˜ëŒ€ê¸ˆ ì¶©ë¶„ì„±
5. ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ë³´ìƒ (Risk/Reward)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "picks": [
        {{
            "stock_code": "ì½”ë“œ",
            "stock_name": "ì¢…ëª©ëª…",
            "rank": ìˆœìœ„,
            "confidence": "HIGH/MEDIUM/LOW",
            "reason": "ì„ ë³„ ì´ìœ  (í•œêµ­ì–´, 2~3ë¬¸ì¥)",
            "risk": "ì£¼ìš” ë¦¬ìŠ¤í¬ (í•œ ë¬¸ì¥)",
            "expected_return": "ê¸°ëŒ€ ìˆ˜ìµë¥  ë²”ìœ„"
        }}
    ],
    "market_view": "ì˜¤ëŠ˜ ì‹œì¥ì— ëŒ€í•œ ì „ì²´ì  í‰ê°€ (í•œêµ­ì–´, í•œ ë¬¸ì¥)",
    "top_themes": ["ì˜¤ëŠ˜ì˜ í•« í…Œë§ˆ 1", "í…Œë§ˆ 2", "í…Œë§ˆ 3"]
}}"""

        try:
            response = await self.client.messages.create(
                model=self.model_name,
                max_tokens=4096,
                system="You are a professional Korean stock market portfolio manager. Respond only in valid JSON. Analyze all candidates comprehensively.",
                messages=[{"role": "user", "content": prompt}],
            )
            content = response.content[0].text.strip()

            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                match = re.search(r"\{.*\}", content, re.DOTALL)
                if match:
                    result = json.loads(match.group())
                else:
                    result = {"picks": [], "error": "JSON parse failed"}

            result["generated_at"] = datetime.now().isoformat()
            result["model"] = self.model_name
            return result

        except Exception as e:
            print(f"[ERROR] Claude Screener Failed: {e}")
            return {
                "picks": [],
                "error": str(e),
                "generated_at": datetime.now().isoformat(),
                "model": self.model_name
            }

    def _build_candidates_summary(self, signals_data: List[Dict]) -> str:
        """ì‹œê·¸ë„ ë°ì´í„°ë¥¼ Claudeì— ì „ë‹¬í•  ê°„ê²°í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = []
        for i, s in enumerate(signals_data, 1):
            score = s.get("score", {})
            lines.append(
                f"#{i} [{s.get('grade','?')}] {s.get('stock_name','')}({s.get('stock_code','')}) "
                f"| ë“±ë½: {s.get('change_pct', 0):+.1f}% "
                f"| ê±°ë˜ëŒ€ê¸ˆ: {s.get('trading_value', 0) / 100_000_000:.0f}ì–µ "
                f"| ì ìˆ˜: {score.get('total', 0)} "
                f"(ë‰´ìŠ¤{score.get('news',0)} ìˆ˜ê¸‰{score.get('supply',0)} ì°¨íŠ¸{score.get('chart',0)} ê±°ë˜ëŸ‰{score.get('volume',0)}) "
                f"| ì™¸ì¸5d: {s.get('foreign_5d', 0):+,} ê¸°ê´€5d: {s.get('inst_5d', 0):+,} "
                f"| AI: {score.get('llm_reason', 'N/A')[:80]} "
                f"| í…Œë§ˆ: {', '.join(s.get('themes', []))}"
            )
        return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Multi-AI Consensus Screening System
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class BaseScreener:
    """AI ìŠ¤í¬ë¦¬ë„ˆ ê³µí†µ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def _build_candidates_summary(self, signals_data: List[Dict]) -> str:
        """ì‹œê·¸ë„ ë°ì´í„°ë¥¼ AIì— ì „ë‹¬í•  ê°„ê²°í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = []
        for i, s in enumerate(signals_data, 1):
            score = s.get("score", {})
            disc = s.get("disclosure_info", {})
            disc_text = ""
            if disc.get("has_disclosure"):
                disc_text = f" | ê³µì‹œ: {', '.join(disc.get('types', []))}"
            lines.append(
                f"#{i} [{s.get('grade','?')}] {s.get('stock_name','')}({s.get('stock_code','')}) "
                f"| ë“±ë½: {s.get('change_pct', 0):+.1f}% "
                f"| ê±°ë˜ëŒ€ê¸ˆ: {s.get('trading_value', 0) / 100_000_000:.0f}ì–µ "
                f"| ì ìˆ˜: {score.get('total', 0)} "
                f"(ë‰´ìŠ¤{score.get('news',0)} ìˆ˜ê¸‰{score.get('supply',0)} ì°¨íŠ¸{score.get('chart',0)} "
                f"ê±°ë˜ëŸ‰{score.get('volume',0)} ê³µì‹œ{score.get('disclosure',0)}) "
                f"| ì™¸ì¸5d: {s.get('foreign_5d', 0):+,} ê¸°ê´€5d: {s.get('inst_5d', 0):+,} "
                f"| AI: {score.get('llm_reason', 'N/A')[:80]} "
                f"| í…Œë§ˆ: {', '.join(s.get('themes', []))}"
                f"{disc_text}"
            )
        return "\n".join(lines)

    def _build_screening_prompt(self, candidates_text: str, count: int) -> str:
        """ìŠ¤í¬ë¦¬ë‹ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ì˜¤ëŠ˜ì˜ ì¢…ê°€ë² íŒ…(Closing Bet) ì‹œê·¸ë„ í›„ë³´ ì¢…ëª© {count}ê°œì˜ ë°ì´í„°ì…ë‹ˆë‹¤.

[í›„ë³´ ì¢…ëª© ë°ì´í„°]
{candidates_text}

ìœ„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì¢… Top 10~15 ì¢…ëª©ì„ ì„ ë³„í•´ì£¼ì„¸ìš”.

ì„ ë³„ ê¸°ì¤€:
1. ë‰´ìŠ¤/ì¬ë£Œì˜ ì§ˆì  ìˆ˜ì¤€ (ë‹¨ìˆœ í…Œë§ˆ vs ì‹¤ì /ìˆ˜ì£¼)
2. ìˆ˜ê¸‰ íë¦„ (ì™¸ì¸+ê¸°ê´€ ë™ì‹œ ë§¤ìˆ˜ ìš°ì„ )
3. ì°¨íŠ¸ ê¸°ìˆ ì  ìœ„ì¹˜ (ì‹ ê³ ê°€/ëŒíŒŒ/ì •ë°°ì—´)
4. ê±°ë˜ëŒ€ê¸ˆ ì¶©ë¶„ì„±
5. ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ë³´ìƒ (Risk/Reward)
6. DART ê³µì‹œ ì •ë³´ (ìì‚¬ì£¼ì·¨ë“, ë¬´ìƒì¦ì, ëŒ€ê·œëª¨ìˆ˜ì£¼ ë“± í˜¸ì¬ê³µì‹œ ìš°ì„ )

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "picks": [
        {{
            "stock_code": "ì½”ë“œ",
            "stock_name": "ì¢…ëª©ëª…",
            "rank": ìˆœìœ„,
            "confidence": "HIGH/MEDIUM/LOW",
            "reason": "ì„ ë³„ ì´ìœ  (í•œêµ­ì–´, 2~3ë¬¸ì¥)",
            "risk": "ì£¼ìš” ë¦¬ìŠ¤í¬ (í•œ ë¬¸ì¥)",
            "expected_return": "ê¸°ëŒ€ ìˆ˜ìµë¥  ë²”ìœ„"
        }}
    ],
    "market_view": "ì˜¤ëŠ˜ ì‹œì¥ì— ëŒ€í•œ ì „ì²´ì  í‰ê°€ (í•œêµ­ì–´, í•œ ë¬¸ì¥)",
    "top_themes": ["ì˜¤ëŠ˜ì˜ í•« í…Œë§ˆ 1", "í…Œë§ˆ 2", "í…Œë§ˆ 3"]
}}"""

    def _parse_json_response(self, content: str) -> dict:
        """JSON ì‘ë‹µ íŒŒì‹± (regex fallback í¬í•¨)"""
        try:
            result = json.loads(content)
        except json.JSONDecodeError:
            match = re.search(r"\{.*\}", content, re.DOTALL)
            if match:
                try:
                    result = json.loads(match.group())
                except json.JSONDecodeError:
                    result = {"picks": [], "error": "JSON parse failed"}
            else:
                result = {"picks": [], "error": "JSON parse failed"}
        return result


class GeminiScreener(BaseScreener):
    """Gemini 2.5 Flash ê¸°ë°˜ ë…ë¦½ì  ì¢…ëª© ì„ ë³„ê¸°"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        self.model_name = os.getenv("GEMINI_SCREENER_MODEL", "gemini-2.5-flash")
        self.model = None
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(self.model_name)

    async def screen_candidates(self, signals_data: List[Dict]) -> Dict:
        if not self.model:
            return {"picks": [], "error": "No Gemini Client", "generated_at": datetime.now().isoformat()}
        if not signals_data:
            return {"picks": [], "error": "No signals", "generated_at": datetime.now().isoformat()}

        candidates_text = self._build_candidates_summary(signals_data)
        prompt = self._build_screening_prompt(candidates_text, len(signals_data))

        try:
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            content = response.text.strip()
            result = self._parse_json_response(content)
            result["generated_at"] = datetime.now().isoformat()
            result["model"] = self.model_name
            return result
        except Exception as e:
            print(f"[ERROR] Gemini Screener Failed: {e}")
            return {"picks": [], "error": str(e), "generated_at": datetime.now().isoformat(), "model": self.model_name}


class OpenAIScreener(BaseScreener):
    """GPT-4o ê¸°ë°˜ ë…ë¦½ì  ì¢…ëª© ì„ ë³„ê¸°"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model_name = os.getenv("OPENAI_SCREENER_MODEL", "gpt-4o")
        self.client = None
        if self.api_key:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=self.api_key)

    async def screen_candidates(self, signals_data: List[Dict]) -> Dict:
        if not self.client:
            return {"picks": [], "error": "No OpenAI Client", "generated_at": datetime.now().isoformat()}
        if not signals_data:
            return {"picks": [], "error": "No signals", "generated_at": datetime.now().isoformat()}

        candidates_text = self._build_candidates_summary(signals_data)
        prompt = self._build_screening_prompt(candidates_text, len(signals_data))

        try:
            response = await self.client.chat.completions.create(
                model=self.model_name,
                max_tokens=4096,
                messages=[
                    {"role": "system", "content": "You are a professional Korean stock market portfolio manager. Respond only in valid JSON. Analyze all candidates comprehensively."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content.strip()
            result = self._parse_json_response(content)
            result["generated_at"] = datetime.now().isoformat()
            result["model"] = self.model_name
            return result
        except Exception as e:
            print(f"[ERROR] OpenAI Screener Failed: {e}")
            return {"picks": [], "error": str(e), "generated_at": datetime.now().isoformat(), "model": self.model_name}


class MultiAIConsensusScreener:
    """Multi-AI Consensus ì¢…ëª© ì„ ë³„ê¸°

    Gemini + OpenAI ë‘ AIê°€ ë…ë¦½ì ìœ¼ë¡œ ì¢…ëª©ì„ ì„ ë³„í•œ ë’¤,
    ì–‘ìª½ ëª¨ë‘ ì„ íƒí•œ ì¢…ëª©(Consensus)ì„ ìš°ì„  ì¶”ì²œí•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.gemini_screener = GeminiScreener()
        self.openai_screener = OpenAIScreener()

    async def screen_candidates(self, signals_data: List[Dict]) -> Dict:
        """ë‘ AIë¥¼ ë³‘ë ¬ ì‹¤í–‰í•˜ê³  Consensus ê²°ê³¼ ë°˜í™˜"""
        if not signals_data:
            return {
                "picks": [], "consensus_count": 0,
                "gemini_count": 0, "openai_count": 0,
                "market_view": "", "top_themes": [],
                "generated_at": datetime.now().isoformat(),
                "models": [], "consensus_method": "multi_ai"
            }

        # 1. ë³‘ë ¬ ì‹¤í–‰
        gemini_result, openai_result = await asyncio.gather(
            self._safe_screen(self.gemini_screener, signals_data),
            self._safe_screen(self.openai_screener, signals_data),
        )

        # 2. í•©ì˜ ë„ì¶œ
        return self._build_consensus(gemini_result, openai_result)

    async def _safe_screen(self, screener, signals_data: List[Dict], timeout: int = 60) -> Dict:
        """ê°œë³„ ìŠ¤í¬ë¦¬ë„ˆ (íƒ€ì„ì•„ì›ƒ + ì—ëŸ¬ í•¸ë“¤ë§)"""
        try:
            return await asyncio.wait_for(
                screener.screen_candidates(signals_data),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            model_name = getattr(screener, 'model_name', 'unknown')
            print(f"[TIMEOUT] {model_name} Screener timed out after {timeout}s")
            return {"picks": [], "error": f"Timeout after {timeout}s", "model": model_name}
        except Exception as e:
            model_name = getattr(screener, 'model_name', 'unknown')
            print(f"[ERROR] {model_name} Screener Failed: {e}")
            return {"picks": [], "error": str(e), "model": model_name}

    def _build_consensus(self, gemini_result: Dict, openai_result: Dict) -> Dict:
        """ë‘ AI ê²°ê³¼ë¥¼ í•©ì˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë³‘í•©"""
        gemini_picks = gemini_result.get("picks", [])
        openai_picks = openai_result.get("picks", [])

        # stock_code ê¸°ë°˜ ë§¤í•‘
        gemini_map = {p.get("stock_code", ""): p for p in gemini_picks if p.get("stock_code")}
        openai_map = {p.get("stock_code", ""): p for p in openai_picks if p.get("stock_code")}

        gemini_codes = set(gemini_map.keys())
        openai_codes = set(openai_map.keys())

        # êµì§‘í•© = Consensus
        consensus_codes = gemini_codes & openai_codes
        gemini_only_codes = gemini_codes - openai_codes
        openai_only_codes = openai_codes - gemini_codes

        # Consensus picks (ì–‘ìª½ í•©ì˜ â†’ confidence ìƒí–¥)
        consensus_picks = []
        for code in sorted(consensus_codes, key=lambda c: self._consensus_sort_key(gemini_map[c], openai_map[c])):
            merged = self._merge_pick(gemini_map[code], openai_map[code])
            consensus_picks.append(merged)

        # Single-AI picks (í•œìª½ë§Œ â†’ confidence í•˜í–¥)
        gemini_only = []
        for code in sorted(gemini_only_codes, key=lambda c: gemini_map[c].get("rank", 99)):
            pick = gemini_map[code].copy()
            pick["source"] = "gemini_only"
            pick["confidence"] = self._downgrade_confidence(pick.get("confidence", "LOW"))
            gemini_only.append(pick)

        openai_only = []
        for code in sorted(openai_only_codes, key=lambda c: openai_map[c].get("rank", 99)):
            pick = openai_map[code].copy()
            pick["source"] = "openai_only"
            pick["confidence"] = self._downgrade_confidence(pick.get("confidence", "LOW"))
            openai_only.append(pick)

        # í†µí•© + ì¬ìˆœìœ„
        all_picks = consensus_picks + gemini_only + openai_only
        for i, p in enumerate(all_picks, 1):
            p["rank"] = i

        # Market views ë³‘í•©
        views = []
        if gemini_result.get("market_view"):
            views.append(f"[Gemini] {gemini_result['market_view']}")
        if openai_result.get("market_view"):
            views.append(f"[GPT-4o] {openai_result['market_view']}")

        # Themes ë³‘í•© (ì¤‘ë³µ ì œê±°)
        all_themes = []
        for t in (gemini_result.get("top_themes", []) + openai_result.get("top_themes", [])):
            if t not in all_themes:
                all_themes.append(t)

        # í™œì„± ëª¨ë¸
        models_used = []
        if gemini_picks:
            models_used.append(gemini_result.get("model", "gemini-2.5-flash"))
        if openai_picks:
            models_used.append(openai_result.get("model", "gpt-4o"))

        return {
            "picks": all_picks,
            "consensus_count": len(consensus_picks),
            "gemini_count": len(gemini_picks),
            "openai_count": len(openai_picks),
            "market_view": " | ".join(views),
            "top_themes": all_themes[:6],
            "generated_at": datetime.now().isoformat(),
            "models": models_used,
            "consensus_method": "multi_ai",
        }

    def _consensus_sort_key(self, gp: Dict, op: Dict) -> tuple:
        """Consensus ì •ë ¬ í‚¤ (ë†’ì€ confidence + ë‚®ì€ avg rank ìš°ì„ )"""
        conf_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2}
        avg_rank = (gp.get("rank", 99) + op.get("rank", 99)) / 2
        best_conf = min(
            conf_order.get(gp.get("confidence", "LOW"), 2),
            conf_order.get(op.get("confidence", "LOW"), 2)
        )
        return (best_conf, avg_rank)

    def _merge_pick(self, gp: Dict, op: Dict) -> Dict:
        """ì–‘ìª½ AI ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•© (confidence ìƒí–¥)"""
        conf_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2}
        reverse = {0: "HIGH", 1: "MEDIUM", 2: "LOW"}

        g_conf = conf_order.get(gp.get("confidence", "LOW"), 2)
        o_conf = conf_order.get(op.get("confidence", "LOW"), 2)
        best = min(g_conf, o_conf)
        boosted = max(0, best - 1)  # 1ë‹¨ê³„ ìƒí–¥

        return {
            "stock_code": gp.get("stock_code", ""),
            "stock_name": gp.get("stock_name", op.get("stock_name", "")),
            "rank": 0,  # ë‚˜ì¤‘ì— ì¬ë°°ì •
            "confidence": reverse[boosted],
            "reason": f"[Gemini] {gp.get('reason', '')} [GPT-4o] {op.get('reason', '')}",
            "risk": gp.get("risk", op.get("risk", "")),
            "expected_return": gp.get("expected_return", op.get("expected_return", "")),
            "source": "consensus",
            "gemini_rank": gp.get("rank", 99),
            "openai_rank": op.get("rank", 99),
        }

    def _downgrade_confidence(self, confidence: str) -> str:
        """Single-AI picks confidence 1ë‹¨ê³„ í•˜í–¥"""
        downgrades = {"HIGH": "MEDIUM", "MEDIUM": "LOW", "LOW": "LOW"}
        return downgrades.get(confidence, "LOW")


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    async def test():
        analyzer = LLMAnalyzer()
        print("ğŸ” ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘: ì‚¼ì„±ì „ì")
        result = await analyzer.analyze_news_sentiment("ì‚¼ì„±ì „ì", [])
        print(json.dumps(result, indent=2, ensure_ascii=False))

    asyncio.run(test())
