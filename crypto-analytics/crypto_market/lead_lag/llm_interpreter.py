#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lead-Lag Analysis - LLM Interpreter Module
Uses Gemini to provide natural language interpretation of quantitative results.

ULTRATHINK Design:
- Takes statistical results as input
- Generates investment insights in Korean/English
- Identifies limitations and caveats
- Suggests additional indicators to monitor
"""
import os
import logging
from typing import Dict, List, Optional
import json

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def get_gemini_model():
    """Initialize Gemini model"""
    try:
        import google.generativeai as genai
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv("GOOGLE_API_KEY")
        
        if not api_key:
            logger.error("GOOGLE_API_KEY not found in environment")
            return None
        
        genai.configure(api_key=api_key)
        return genai.GenerativeModel("gemini-3-flash-preview")
        
    except ImportError:
        logger.error("google-generativeai not installed")
        return None
    except Exception as e:
        logger.error(f"Failed to initialize Gemini: {e}")
        return None


def interpret_lead_lag_results(
    results: List[Dict],
    target: str = "BTC",
    current_conditions: Optional[Dict] = None,
    lang: str = "ko"
) -> str:
    """
    Use LLM to interpret lead-lag analysis results.
    
    Args:
        results: List of analysis results (from LeadLagResult.to_dict())
        target: Target variable being analyzed
        current_conditions: Current values of indicators (optional)
        lang: Output language ('ko' or 'en')
    
    Returns:
        LLM-generated interpretation
    """
    model = get_gemini_model()
    
    if model is None:
        return _fallback_interpretation(results, target, lang)
    
    # Format results for LLM
    results_text = json.dumps(results, indent=2, ensure_ascii=False)
    
    if lang == "ko":
        prompt = f"""
ë‹¹ì‹ ì€ ë§¤í¬ë¡œ ê²½ì œì™€ ì•”í˜¸í™”í ì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ Lead-Lag ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³  íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ëŒ€ìƒ: {target}

## Lead-Lag ë¶„ì„ ê²°ê³¼:
{results_text}

## í˜„ì¬ ì‹œì¥ ìƒí™©:
{json.dumps(current_conditions, indent=2, ensure_ascii=False) if current_conditions else "ì •ë³´ ì—†ìŒ"}

## ìš”ì²­ ì‚¬í•­:
1. **í•µì‹¬ ë°œê²¬ì‚¬í•­**: ê°€ì¥ ì¤‘ìš”í•œ ì„ í–‰/í›„í–‰ ê´€ê³„ 3ê°€ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
2. **íˆ¬ì ì‹œì‚¬ì **: í˜„ì¬ ì„ í–‰ì§€í‘œë“¤ì˜ ìƒíƒœë¥¼ ê³ ë ¤í•  ë•Œ {target}ì˜ í–¥í›„ ì „ë§ì€?
3. **ì£¼ì˜ì‚¬í•­**: ì´ ë¶„ì„ì˜ í•œê³„ì ê³¼ ì£¼ì˜í•´ì•¼ í•  ì 
4. **ì¶”ê°€ ëª¨ë‹ˆí„°ë§**: ì¶”ê°€ë¡œ í™•ì¸í•´ì•¼ í•  ì§€í‘œë‚˜ ì´ë²¤íŠ¸

ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
"""
    else:
        prompt = f"""
You are an expert in macroeconomics and cryptocurrency markets.
Interpret the following Lead-Lag correlation analysis results and provide investment insights.

## Target Asset: {target}

## Lead-Lag Analysis Results:
{results_text}

## Current Market Conditions:
{json.dumps(current_conditions, indent=2) if current_conditions else "Not provided"}

## Requested Analysis:
1. **Key Findings**: Explain the 3 most important lead-lag relationships.
2. **Investment Implications**: Given current leading indicators, what's the outlook for {target}?
3. **Caveats**: Limitations and risks of this analysis
4. **Additional Monitoring**: What other indicators or events should be tracked?

Please provide concise, actionable insights.
"""
    
    try:
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        logger.error(f"LLM interpretation failed: {e}")
        return _fallback_interpretation(results, target, lang)


def interpret_granger_results(
    granger_results: List[Dict],
    target: str = "BTC",
    lang: str = "ko"
) -> str:
    """
    Use LLM to interpret Granger causality results.
    """
    model = get_gemini_model()
    
    if model is None:
        return _fallback_granger_interpretation(granger_results, target, lang)
    
    results_text = json.dumps(granger_results, indent=2, ensure_ascii=False)
    
    if lang == "ko":
        prompt = f"""
ë‹¹ì‹ ì€ ê³„ëŸ‰ê²½ì œí•™ê³¼ ì‹œê³„ì—´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ Granger ì¸ê³¼ê´€ê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ëŒ€ìƒ: {target}

## Granger ì¸ê³¼ê´€ê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:
{results_text}

## ì„¤ëª…:
- Granger ì¸ê³¼ê´€ê³„ë€: ê³¼ê±° ê°’ì´ ë¯¸ë˜ ì˜ˆì¸¡ì— ë„ì›€ì´ ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
- p-value < 0.05: í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì˜ˆì¸¡ë ¥ ì¡´ì¬
- best_lag: ê°€ì¥ ê°•í•œ ì˜ˆì¸¡ë ¥ì„ ë³´ì´ëŠ” ì‹œì°¨

## ìš”ì²­:
1. ì–´ë–¤ ì§€í‘œê°€ {target}ì„ ê°€ì¥ ì˜ ì˜ˆì¸¡í•˜ë‚˜ìš”?
2. ê° ì§€í‘œì˜ ì˜ˆì¸¡ ì‹œì°¨(lag)ëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?
3. ì‹¤ì œ íŠ¸ë ˆì´ë”©ì— ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆë‚˜ìš”?
4. ì£¼ì˜í•´ì•¼ í•  ì ì€?

ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
    else:
        prompt = f"""
You are an expert in econometrics and time series analysis.
Interpret the following Granger causality test results.

## Target Asset: {target}

## Granger Causality Test Results:
{results_text}

## Context:
- Granger causality tests whether past values help predict future values
- p-value < 0.05: Statistically significant predictive power
- best_lag: The lag with strongest predictive power

## Please explain:
1. Which indicators best predict {target}?
2. What do the lag periods mean for each indicator?
3. How can this be used in trading?
4. What are the caveats?

Please provide concise, practical insights.
"""
    
    try:
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        logger.error(f"LLM interpretation failed: {e}")
        return _fallback_granger_interpretation(granger_results, target, lang)


def generate_trading_signal_interpretation(
    lead_lag_results: List[Dict],
    current_values: Dict,
    target: str = "BTC",
    lang: str = "ko"
) -> str:
    """
    Generate trading signal based on current leading indicator values.
    """
    model = get_gemini_model()
    
    if model is None:
        return "LLM unavailable for signal generation"
    
    if lang == "ko":
        prompt = f"""
ë‹¹ì‹ ì€ í€€íŠ¸ íŠ¸ë ˆì´ë”ì…ë‹ˆë‹¤.
Lead-Lag ë¶„ì„ ê²°ê³¼ì™€ í˜„ì¬ ì„ í–‰ì§€í‘œ ê°’ì„ ë°”íƒ•ìœ¼ë¡œ {target}ì— ëŒ€í•œ ì‹ í˜¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## Lead-Lag ê´€ê³„:
{json.dumps(lead_lag_results, indent=2, ensure_ascii=False)}

## í˜„ì¬ ì„ í–‰ì§€í‘œ ê°’:
{json.dumps(current_values, indent=2, ensure_ascii=False)}

## ë¶„ì„ ìš”ì²­:
1. **ì‹ í˜¸**: BULLISH / BEARISH / NEUTRAL ì¤‘ í•˜ë‚˜
2. **ì‹ ë¢°ë„**: 1-10ì 
3. **ì˜ˆìƒ ì‹œì **: ì–¸ì œì¯¤ {target}ì— ì˜í–¥ì´ ë‚˜íƒ€ë‚ ì§€
4. **ê·¼ê±°**: ì–´ë–¤ ì„ í–‰ì§€í‘œê°€ ì´ ì‹ í˜¸ë¥¼ ì§€ì§€í•˜ëŠ”ì§€
5. **ë¦¬ìŠ¤í¬**: ì´ ì‹ í˜¸ê°€ í‹€ë¦´ ìˆ˜ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{{
  "signal": "BULLISH/BEARISH/NEUTRAL",
  "confidence": 7,
  "expected_timing": "1-2ê°œì›” í›„",
  "rationale": "...",
  "risk_factors": ["..."]
}}
"""
    else:
        prompt = f"""
You are a quant trader.
Generate a signal for {target} based on lead-lag analysis and current indicator values.

## Lead-Lag Relationships:
{json.dumps(lead_lag_results, indent=2)}

## Current Leading Indicator Values:
{json.dumps(current_values, indent=2)}

## Please provide:
1. **Signal**: BULLISH / BEARISH / NEUTRAL
2. **Confidence**: 1-10 scale
3. **Expected Timing**: When the effect should materialize
4. **Rationale**: Which indicators support this signal
5. **Risks**: Scenarios where this could be wrong

Reply in JSON format:
{{
  "signal": "BULLISH/BEARISH/NEUTRAL",
  "confidence": 7,
  "expected_timing": "1-2 months",
  "rationale": "...",
  "risk_factors": ["..."]
}}
"""
    
    try:
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        logger.error(f"Signal generation failed: {e}")
        return '{"signal": "NEUTRAL", "confidence": 1, "error": "LLM unavailable"}'


def _fallback_interpretation(results: List[Dict], target: str, lang: str) -> str:
    """Fallback interpretation when LLM is unavailable"""
    if lang == "ko":
        lines = [f"## {target} Lead-Lag ë¶„ì„ ê²°ê³¼ ìš”ì•½\n"]
        
        for r in results[:5]:
            lag = r.get('optimal_lag', 0)
            corr = r.get('optimal_correlation', 0)
            var1 = r.get('var1', 'Unknown')
            
            if lag > 0:
                lines.append(f"- **{var1}**: {target}ë³´ë‹¤ {lag}ê¸°ê°„ ì„ í–‰ (ìƒê´€ê³„ìˆ˜: {corr:.3f})")
            elif lag < 0:
                lines.append(f"- **{var1}**: {target}ë³´ë‹¤ {-lag}ê¸°ê°„ í›„í–‰ (ìƒê´€ê³„ìˆ˜: {corr:.3f})")
            else:
                lines.append(f"- **{var1}**: {target}ê³¼ ë™ì‹œ ë³€ë™ (ìƒê´€ê³„ìˆ˜: {corr:.3f})")
        
        return "\n".join(lines)
    else:
        lines = [f"## {target} Lead-Lag Analysis Summary\n"]
        
        for r in results[:5]:
            lag = r.get('optimal_lag', 0)
            corr = r.get('optimal_correlation', 0)
            var1 = r.get('var1', 'Unknown')
            
            if lag > 0:
                lines.append(f"- **{var1}**: Leads {target} by {lag} periods (corr: {corr:.3f})")
            elif lag < 0:
                lines.append(f"- **{var1}**: Lags {target} by {-lag} periods (corr: {corr:.3f})")
            else:
                lines.append(f"- **{var1}**: Moves with {target} simultaneously (corr: {corr:.3f})")
        
        return "\n".join(lines)


def _fallback_granger_interpretation(results: List[Dict], target: str, lang: str) -> str:
    """Fallback interpretation for Granger results"""
    if lang == "ko":
        lines = [f"## {target} Granger ì¸ê³¼ê´€ê³„ ë¶„ì„ ìš”ì•½\n"]
        
        for r in results:
            cause = r.get('cause', 'Unknown')
            p_val = r.get('best_p_value', 1.0)
            lag = r.get('best_lag', 0)
            
            if p_val < 0.05:
                lines.append(f"- **{cause}** â†’ {target}: {lag}ê¸°ê°„ ì„ í–‰í•˜ì—¬ ì˜ˆì¸¡ ê°€ëŠ¥ (p={p_val:.4f})")
        
        return "\n".join(lines) if len(lines) > 1 else "ìœ ì˜í•œ Granger ì¸ê³¼ê´€ê³„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    else:
        lines = [f"## {target} Granger Causality Summary\n"]
        
        for r in results:
            cause = r.get('cause', 'Unknown')
            p_val = r.get('best_p_value', 1.0)
            lag = r.get('best_lag', 0)
            
            if p_val < 0.05:
                lines.append(f"- **{cause}** â†’ {target}: Predicts at {lag} periods ahead (p={p_val:.4f})")
        
        return "\n".join(lines) if len(lines) > 1 else "No significant Granger-causal relationships found."


if __name__ == "__main__":
    print("\nğŸ¤– LLM Interpreter Test\n")
    
    # Test with sample results
    sample_results = [
        {"var1": "DXY", "var2": "BTC", "optimal_lag": -2, "optimal_correlation": -0.45},
        {"var1": "M2", "var2": "BTC", "optimal_lag": 6, "optimal_correlation": 0.61},
        {"var1": "VIX", "var2": "BTC", "optimal_lag": 0, "optimal_correlation": -0.52},
    ]
    
    interpretation = interpret_lead_lag_results(sample_results, "BTC", lang="ko")
    print(interpretation)
